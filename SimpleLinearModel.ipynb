{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetMidiSlices(fileName):\n",
    "    midiArray=[]\n",
    "    HopSize=hopLength/sr\n",
    "    timeTracker=0.0\n",
    "    totalTimeTracker=0.0\n",
    "    MemoryArray=np.zeros(128)\n",
    "    lasttime=0;\n",
    "    bpm=60\n",
    "    for msg in mido.MidiFile(fileName+'.mid'):\n",
    "        if not msg.is_meta:\n",
    "            totalTimeTracker+=msg.time\n",
    "            nextEventTime=lasttime+msg.time\n",
    "            while nextEventTime> timeTracker + HopSize:\n",
    "                MemoryArray[127]=((timeTracker%4) * (bpm/60.0))/4.0\n",
    "                midiArray.append(MemoryArray.copy())\n",
    "                timeTracker += HopSize;\n",
    "            if msg.type=='note_on':\n",
    "                MemoryArray[msg.note]+=1.0;\n",
    "            elif msg.type=='note_off':\n",
    "                MemoryArray[msg.note]-=1.0;\n",
    "            if(timeTracker+msg.time >= timeTracker + HopSize):\n",
    "                MemoryArray[127]=((timeTracker%4) * (bpm/60.0))/4.0\n",
    "                midiArray.append(MemoryArray.copy())\n",
    "                timeTracker += HopSize\n",
    "            lasttime += msg.time\n",
    "        else:\n",
    "            if(msg.type == 'set_tempo'):\n",
    "                bpm=60000000/msg.tempo\n",
    "    return np.array(midiArray)\n",
    "\n",
    "def CreateSeqeunce(dataArray,SeqeunceLen):\n",
    "    OutArray=[]\n",
    "    for i in range(np.int(np.floor(dataArray.shape[0]/SeqeunceLen))):\n",
    "        tempArray=[]\n",
    "        for j in range(SeqeunceLen):\n",
    "            tempArray.append(dataArray[(i*SeqeunceLen)+j])\n",
    "        OutArray.append(tempArray)\n",
    "    return np.array(OutArray)\n",
    "\n",
    "def generateAudio(stringInput,fileName):\n",
    "    print(\"generating audio and Spectrum image\")\n",
    "    MainMidiTest=CreateSeqeunce(GetMidiSlices(stringInput),SequenceLength)\n",
    "    tensor_x_test = torch.stack([torch.Tensor(i) for i in MainMidiTest])\n",
    "    #tensor_x_test = tensor_x_test.view(tensor_x_test.shape[0],-1)\n",
    "    testDataSet = utils.TensorDataset(tensor_x_test,torch.zeros(tensor_x_test.shape)) # create your datset\n",
    "    TestLoader = utils.DataLoader(testDataSet,batch_size=BatchSize) # create your dataloader\n",
    "    model.eval()\n",
    "    outputArray=[]\n",
    "    for data, labels in TestLoader:\n",
    "        print(data.shape)\n",
    "        if data.shape[0] < BatchSize:\n",
    "            zeros = torch.zeros((BatchSize-data.shape[0],SequenceLength,128))\n",
    "            data=torch.cat((data,zeros))\n",
    "        print(data.shape)\n",
    "        with torch.no_grad():\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            output,_,_ = model.forward(data,data.shape[0])\n",
    "            for i in range(data.shape[0]):\n",
    "                for j in range(SequenceLength):\n",
    "                    outputArray.append(output[i,j,:].cpu().numpy())\n",
    "            #outputArray.append(output[0].cpu().numpy())\n",
    "    outputArray=np.array(outputArray)\n",
    "    print(outputArray.shape)\n",
    "    transformedArray=[]\n",
    "    for elem in outputArray:\n",
    "        a=np.array(np.int((n_fft/2+1)) *[1+1j])\n",
    "        a.real=elem[:np.int(n_fft/2+1)]\n",
    "        a.imag=elem[np.int(n_fft/2+1):]\n",
    "        transformedArray.append(a)\n",
    "    transformedArray=np.array(transformedArray).T\n",
    "    Y_infered2 = librosa.istft(transformedArray,hop_length=hopLength) \n",
    "    plt.figure(figsize=(20,10))\n",
    "    \n",
    "    librosa.display.specshow(librosa.amplitude_to_db(transformedArray.real,\n",
    "                                                      ref=np.max),\n",
    "                              y_axis='log', x_axis='time')\n",
    "    plt.title('Power spectrogram  ' + str(Counter) )\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    #plt.show();\n",
    "    plt.savefig(fileName+'.png')\n",
    "    #librosa.output.write_wav(fileName+'.wav', Y_infered2, sr)\n",
    "    plt.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import mido\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import optim\n",
    "import torch.utils.data as utils\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fielName='4Beats2MelLong5'\n",
    "windowSize=50\n",
    "n_fft=2048\n",
    "hopLength=1024\n",
    "SequenceLength = 25 \n",
    "BatchSize=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y, sr = librosa.load(fielName+'.wav')\n",
    "D = np.array(librosa.stft(y,n_fft=n_fft,hop_length=hopLength))\n",
    "\n",
    "MidiArray = GetMidiSlices(fielName)\n",
    "minLength = min(MidiArray.shape[0],D.T.shape[0])\n",
    "MidiArray=MidiArray[:minLength];\n",
    "D_data=np.array([np.append(np.float32(elem.real), np.float32(elem.imag)) for elem in D.T[:minLength]])\n",
    "\n",
    "\n",
    "MidiArray=CreateSeqeunce(MidiArray,SequenceLength)\n",
    "D_data=CreateSeqeunce(D_data,SequenceLength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1025, 53317)\n"
     ]
    }
   ],
   "source": [
    "print(D.shape)\n",
    "Y_SeqeuenceLength = librosa.istft(D[:SequenceLength],hop_length=hopLength)\n",
    "ipd.Audio(Y_SeqeuenceLength,rate=sr);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del y\n",
    "del D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2132, 25, 128) (2132, 25, 2050)\n",
      "float64 float32\n"
     ]
    }
   ],
   "source": [
    "print(MidiArray.shape,D_data.shape)\n",
    "print(MidiArray.dtype,D_data.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fbdbace4c18>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(MidiArray[6,:,127:].T) # visulizing the bea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2132, 25, 128]) torch.Size([2132, 25, 2050])\n",
      "14 4\n"
     ]
    }
   ],
   "source": [
    "tensor_x = torch.stack([torch.Tensor(i) for i in MidiArray]) # transform to torch tensors\n",
    "tensor_y = torch.stack([torch.Tensor(i) for i in np.abs(D_data)])\n",
    "print(tensor_x.shape,tensor_y.shape)\n",
    "\n",
    "my_dataset = utils.TensorDataset(tensor_x,tensor_y) # create your datset\n",
    "\n",
    "train_size = int(0.8 * len(my_dataset))\n",
    "test_size = len(my_dataset) - train_size\n",
    "\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(my_dataset, [train_size, test_size])\n",
    "\n",
    "my_dataloader = utils.DataLoader(train_dataset,batch_size=BatchSize,shuffle=True) # create your dataloader\n",
    "my_validationloader = utils.DataLoader(test_dataset,batch_size=BatchSize,shuffle=True) # create your dataloader\n",
    "print(len(my_dataloader),len(my_validationloader))\n",
    "my_testloader = utils.DataLoader(my_dataset) # create your dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(tensor_x.numpy()[50:100,:,127])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Solution\n",
    "\n",
    "class LSTMNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTMNetwork,self).__init__()\n",
    "        # Defining the layers, 128, 64, 10 units each\n",
    "        \n",
    "        #self.num_layers=1\n",
    "        self.hiddenLayerSize=1024\n",
    "        #self.word_lstm_init_h = nn.Parameter(torch.zeros(self.num_layers, BatchSize, self.hiddenLayerSize).type(torch.FloatTensor), requires_grad=True)\n",
    "        #self.word_lstm_init_c = nn.Parameter(torch.zeros(self.num_layers, BatchSize, self.hiddenLayerSize).type(torch.FloatTensor), requires_grad=True)\n",
    "        #self.word_lstm_init_h.cuda()\n",
    "        #self.word_lstm_init_c.cuda()\n",
    "        #self.fc0 = nn.LSTM(128, self.hiddenLayerSize,num_layers=self.num_layers,batch_first=True)\n",
    "       \n",
    "        self.fc0 = nn.Linear(128, self.hiddenLayerSize)\n",
    "        self.fc1 = nn.Linear(self.hiddenLayerSize, self.hiddenLayerSize*2)\n",
    "        self.fc2 = nn.Linear(self.hiddenLayerSize*2, n_fft+2)\n",
    "        #self.h0 = torch.zeros(self.num_layers, 1, (n_fft+2*2)).cuda() # 2 for bidirection \n",
    "        #self.c0 = torch.zeros(self.num_layers, 1, (n_fft+2*2)).cuda()\n",
    "        \n",
    "\n",
    "    def forward(self, x, ActualBatchSize):\n",
    "        ''' Forward pass through the network, returns the output logits '''\n",
    "        #self.h0=h0\n",
    "        #self.c0=c0 \n",
    "        #x=x.view(SequenceLength,ActualBatchSize,128)\n",
    "        #x,hidden = self.lstm(x,(self.word_lstm_init_h,self.word_lstm_init_c)) #(self.h0,self.c0)\n",
    "        \n",
    "        x = self.fc0(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        return x,0,0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMNetwork(\n",
      "  (fc0): Linear(in_features=128, out_features=1024, bias=True)\n",
      "  (fc1): Linear(in_features=1024, out_features=2048, bias=True)\n",
      "  (fc2): Linear(in_features=2048, out_features=2050, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "##Reset\n",
    "torch.cuda.empty_cache()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = LSTMNetwork()\n",
    "print(model)\n",
    "model.train()\n",
    "model.to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.05,momentum=0.9)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "Counter=0;\n",
    "LossOverEpoch=[]\n",
    "EvalLoss=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.5967233606747218   0  1.1943175196647644\n",
      "Training loss: 1.5586904968534196   1  1.1996497809886932\n",
      "Training loss: 1.5349037732396806   2  1.1877082288265228\n",
      "Training loss: 1.5148061428751265   3  1.179939866065979\n",
      "Training loss: 1.4894642404147558   4  1.1146298348903656\n",
      "Training loss: 1.4631456903048925   5  1.1669538021087646\n",
      "Training loss: 1.467156069619315   6  1.1263677179813385\n",
      "Training loss: 1.4483717935425895   7  1.1084169149398804\n",
      "Training loss: 1.4422283342906408   8  1.1450850665569305\n",
      "Training loss: 1.4420695815767561   9  1.1279402077198029\n",
      "Training loss: 1.434554636478424   10  1.0948781669139862\n",
      "Training loss: 1.4498973659106664   11  1.1098737716674805\n",
      "Training loss: 1.4363704238619124   12  1.1225407123565674\n",
      "Training loss: 1.424544291836875   13  1.109272986650467\n",
      "Training loss: 1.4304825919015067   14  1.1112276315689087\n",
      "Training loss: 1.4369439908436366   15  1.098671317100525\n",
      "Training loss: 1.4303772960390364   16  1.105737566947937\n",
      "Training loss: 1.423904001712799   17  1.1147364974021912\n",
      "Training loss: 1.4316752212388175   18  1.0887426435947418\n",
      "Training loss: 1.4259735941886902   19  1.113666981458664\n",
      "Training loss: 1.4158368451254708   20  1.1080043613910675\n",
      "Training loss: 1.413927205971309   21  1.1031743288040161\n",
      "Training loss: 1.4095706599099296   22  1.088737577199936\n",
      "Training loss: 1.409125336578914   23  1.157344937324524\n",
      "Training loss: 1.4131993651390076   24  1.1271425485610962\n",
      "Training loss: 1.3981233068874903   25  1.0685336589813232\n",
      "Training loss: 1.389385896069663   26  1.0540467202663422\n",
      "Training loss: 1.397892713546753   27  1.0981314778327942\n",
      "Training loss: 1.3980896728379386   28  1.0743091702461243\n",
      "Training loss: 1.3848014559064592   29  1.0761167705059052\n",
      "Training loss: 1.3847766774041312   30  1.0903492867946625\n",
      "Training loss: 1.3813166448048182   31  1.0819826126098633\n",
      "Training loss: 1.3743652190480913   32  1.063599854707718\n",
      "Training loss: 1.3709401147706168   33  1.0478336215019226\n",
      "Training loss: 1.3698813319206238   34  1.0515289306640625\n",
      "Training loss: 1.3712909391948156   35  1.0866115093231201\n",
      "Training loss: 1.359215727874211   36  1.0631290972232819\n",
      "Training loss: 1.354981243610382   37  1.0658072233200073\n",
      "Training loss: 1.3545059050832475   38  1.0670623779296875\n",
      "Training loss: 1.3467086894171578   39  1.0638997256755829\n",
      "Training loss: 1.3436244130134583   40  1.0818405747413635\n",
      "Training loss: 1.3447572078023637   41  1.042065680027008\n",
      "Training loss: 1.3396865214620317   42  1.0219415128231049\n",
      "Training loss: 1.3365425893238612   43  1.0684353113174438\n",
      "Training loss: 1.3317006826400757   44  1.058684915304184\n",
      "Training loss: 1.3254671692848206   45  1.0838493406772614\n",
      "Training loss: 1.320373032774244   46  1.0725974440574646\n",
      "Training loss: 1.3291660973003931   47  0.98413947224617\n",
      "Training loss: 1.3083747625350952   48  1.0411288142204285\n",
      "Training loss: 1.3129499128886633   49  0.9755730926990509\n",
      "Training loss: 1.317601306097848   50  1.0641641318798065\n",
      "Training loss: 1.3155951159340995   51  1.0092560052871704\n",
      "Training loss: 1.3153477140835352   52  1.0410641431808472\n",
      "Training loss: 1.300238013267517   53  1.026058167219162\n",
      "Training loss: 1.296088354928153   54  0.9979356825351715\n",
      "Training loss: 1.300053826400212   55  0.9962563216686249\n",
      "Training loss: 1.3049174462045943   56  1.0116464495658875\n",
      "Training loss: 1.297216066292354   57  1.0179618299007416\n",
      "Training loss: 1.2975511806351798   58  1.0088706612586975\n",
      "Training loss: 1.2883513825280326   59  1.0141555666923523\n",
      "Training loss: 1.28775235584804   60  1.0023809671401978\n",
      "Training loss: 1.2975032329559326   61  1.0311080515384674\n",
      "Training loss: 1.2831963726452418   62  1.003321349620819\n",
      "Training loss: 1.2806562696184431   63  0.9979480504989624\n",
      "Training loss: 1.2829538583755493   64  0.9948619902133942\n",
      "Training loss: 1.269932644707816   65  1.0195052325725555\n",
      "Training loss: 1.279931596347264   66  1.0233888030052185\n",
      "Training loss: 1.283239449773516   67  1.0202059149742126\n",
      "Training loss: 1.2671080487115043   68  1.015709936618805\n",
      "Training loss: 1.266409661088671   69  1.0048998296260834\n",
      "Training loss: 1.2766258546284266   70  1.0195233225822449\n",
      "Training loss: 1.2713332091059004   71  0.9980957806110382\n",
      "Training loss: 1.2715253404208593   72  1.035798043012619\n",
      "Training loss: 1.2645147698266166   73  1.032275676727295\n",
      "Training loss: 1.2540421400751387   74  1.0247872173786163\n",
      "Training loss: 1.2612591215542384   75  0.9768425524234772\n",
      "Training loss: 1.2604981235095434   76  0.9943069219589233\n",
      "Training loss: 1.2648992112704687   77  1.0106165707111359\n",
      "Training loss: 1.2614185980388097   78  0.983033686876297\n",
      "Training loss: 1.2573382599013192   79  1.018608808517456\n",
      "Training loss: 1.260141909122467   80  0.981134831905365\n",
      "Training loss: 1.255891135760716   81  0.9877116978168488\n",
      "Training loss: 1.2510898453848702   82  0.9704892635345459\n",
      "Training loss: 1.256652559552874   83  0.9829660654067993\n",
      "Training loss: 1.260213383606502   84  0.9782146215438843\n",
      "Training loss: 1.2450735654149736   85  0.9652831256389618\n",
      "Training loss: 1.2594617434910365   86  0.9917746782302856\n",
      "Training loss: 1.2395984275000436   87  0.9881168305873871\n",
      "Training loss: 1.2467317070279802   88  1.0300360918045044\n",
      "Training loss: 1.2451023629733495   89  0.9875665009021759\n",
      "Training loss: 1.2503234488623483   90  0.9948317408561707\n",
      "Training loss: 1.248050102165767   91  0.9879093766212463\n",
      "Training loss: 1.2386013439723425   92  1.0094593167304993\n",
      "Training loss: 1.239400063242231   93  0.9520168006420135\n",
      "Training loss: 1.237299186842782   94  0.94903963804245\n",
      "Training loss: 1.2338720985821314   95  1.009194254875183\n",
      "Training loss: 1.2314295087541853   96  0.9843628108501434\n",
      "Training loss: 1.2367373704910278   97  0.97420933842659\n",
      "Training loss: 1.2302633949688502   98  0.9557197690010071\n",
      "Training loss: 1.2345643213817052   99  0.9799185991287231\n",
      "Training loss: 1.2349836230278015   100  0.962355226278305\n",
      "Training loss: 1.240170453275953   101  1.001203566789627\n",
      "Training loss: 1.2319242443357195   102  0.984543651342392\n",
      "Training loss: 1.2396230271884374   103  0.9910282492637634\n",
      "Training loss: 1.2291453565870012   104  0.9936154186725616\n",
      "Training loss: 1.2298270549092973   105  0.9471791088581085\n",
      "Training loss: 1.2197301813534327   106  0.9701927602291107\n",
      "Training loss: 1.2132965922355652   107  0.955403596162796\n",
      "Training loss: 1.21838059595653   108  0.9647632241249084\n",
      "Training loss: 1.2144807832581657   109  0.9919329881668091\n",
      "Training loss: 1.2123964088303703   110  0.9669233858585358\n",
      "Training loss: 1.220180298600878   111  0.9657982885837555\n",
      "Training loss: 1.2092597058841161   112  0.9571815133094788\n",
      "Training loss: 1.2067972251347132   113  0.9671685695648193\n",
      "Training loss: 1.2044816528047835   114  0.9304435551166534\n",
      "Training loss: 1.2141169565064567   115  0.9729170203208923\n",
      "Training loss: 1.2071315731321062   116  0.9516454041004181\n",
      "Training loss: 1.2027513980865479   117  0.9453366696834564\n",
      "Training loss: 1.210076825959342   118  0.9934182465076447\n",
      "Training loss: 1.2035703659057617   119  0.9486543238162994\n",
      "Training loss: 1.1979435256549291   120  0.9582070112228394\n",
      "Training loss: 1.198443055152893   121  0.9396794736385345\n",
      "Training loss: 1.1992263197898865   122  0.9841435253620148\n",
      "Training loss: 1.1971656339509147   123  0.9534178972244263\n",
      "Training loss: 1.2054887669427055   124  0.9634369909763336\n",
      "Training loss: 1.1978336913245065   125  0.9504868686199188\n",
      "Training loss: 1.2093371152877808   126  0.9586671888828278\n",
      "Training loss: 1.1975197536604745   127  0.9206290245056152\n",
      "Training loss: 1.1862352405275618   128  0.9159515202045441\n",
      "Training loss: 1.182606305394854   129  0.9441904127597809\n",
      "Training loss: 1.1802823628698076   130  0.940118819475174\n",
      "Training loss: 1.184128156730107   131  0.9345688819885254\n",
      "Training loss: 1.1865249957357134   132  0.9486976563930511\n",
      "Training loss: 1.1850937349455697   133  0.9532642364501953\n",
      "Training loss: 1.175913725580488   134  0.9449410736560822\n",
      "Training loss: 1.172470075743539   135  0.9381783306598663\n",
      "Training loss: 1.1688867211341858   136  0.9647578597068787\n",
      "Training loss: 1.1770769953727722   137  0.9400489628314972\n",
      "Training loss: 1.169593789747783   138  0.9443262815475464\n",
      "Training loss: 1.1727333153997148   139  0.9090471863746643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.162064186164311   140  0.9366197884082794\n",
      "Training loss: 1.1514910204069955   141  0.9651192724704742\n",
      "Training loss: 1.1659173965454102   142  0.9314466118812561\n",
      "Training loss: 1.1614309889929635   143  0.9073417484760284\n",
      "Training loss: 1.163873314857483   144  0.9755747616291046\n",
      "Training loss: 1.1574561425617762   145  0.9417266249656677\n",
      "Training loss: 1.157548955508641   146  0.9317923188209534\n",
      "Training loss: 1.1698097501482283   147  0.9062581956386566\n",
      "Training loss: 1.156965093953269   148  0.8822821974754333\n",
      "Training loss: 1.160595680986132   149  0.9185265004634857\n",
      "Training loss: 1.1456435833658491   150  0.8945097625255585\n",
      "Training loss: 1.1486323475837708   151  0.9542069435119629\n",
      "Training loss: 1.1495436940874373   152  0.9333077073097229\n",
      "Training loss: 1.151583296912057   153  0.9142556488513947\n",
      "Training loss: 1.1548954844474792   154  0.9228047132492065\n",
      "Training loss: 1.146565590585981   155  0.88870769739151\n",
      "Training loss: 1.1408706733158656   156  0.9251941740512848\n",
      "Training loss: 1.1284769943782262   157  0.8790799677371979\n",
      "Training loss: 1.1282092545713698   158  0.9202396869659424\n",
      "Training loss: 1.1286764655794417   159  0.8975029587745667\n",
      "Training loss: 1.1252571259226118   160  0.8855513036251068\n",
      "Training loss: 1.1206660185541426   161  0.929571270942688\n",
      "Training loss: 1.1279341237885612   162  0.9125589728355408\n",
      "Training loss: 1.1310551762580872   163  0.9174900054931641\n",
      "Training loss: 1.1348352006503515   164  0.9201042652130127\n",
      "Training loss: 1.1292652998651778   165  0.8956549763679504\n",
      "Training loss: 1.1117826700210571   166  0.8875565230846405\n",
      "Training loss: 1.117302085672106   167  0.8889864385128021\n",
      "Training loss: 1.1096041117395674   168  0.8929996192455292\n",
      "Training loss: 1.1047816787447249   169  0.8930225968360901\n",
      "Training loss: 1.1075132829802377   170  0.8868359625339508\n",
      "Training loss: 1.1005232078688485   171  0.8784342706203461\n",
      "Training loss: 1.09830561705998   172  0.8942207992076874\n",
      "Training loss: 1.0952423300061906   173  0.902412474155426\n",
      "Training loss: 1.0990615487098694   174  0.8836731910705566\n",
      "Training loss: 1.0889819008963448   175  0.8706552684307098\n",
      "Training loss: 1.0902055587087358   176  0.8763158917427063\n",
      "Training loss: 1.0929327862603324   177  0.8551477789878845\n",
      "Training loss: 1.0917170558656966   178  0.874725729227066\n",
      "Training loss: 1.0792681787695204   179  0.8663821816444397\n",
      "Training loss: 1.0733452779906136   180  0.8591019809246063\n",
      "Training loss: 1.0797178447246552   181  0.8960714638233185\n",
      "Training loss: 1.0744624904223852   182  0.8700323104858398\n",
      "Training loss: 1.0708667125020708   183  0.8504382520914078\n",
      "Training loss: 1.0742737991469247   184  0.8581875860691071\n",
      "Training loss: 1.0689296764986855   185  0.8498713970184326\n",
      "Training loss: 1.0698539486953191   186  0.8654859066009521\n",
      "Training loss: 1.0654604647840773   187  0.8486484885215759\n",
      "Training loss: 1.059622538941247   188  0.8249233663082123\n",
      "Training loss: 1.0635389941079276   189  0.8694924712181091\n",
      "Training loss: 1.0558216912405831   190  0.838306337594986\n",
      "Training loss: 1.0571412146091461   191  0.850818544626236\n",
      "Training loss: 1.050848820379802   192  0.8537372648715973\n",
      "Training loss: 1.0570096969604492   193  0.8412138819694519\n",
      "Training loss: 1.0450297679219926   194  0.8500410616397858\n",
      "Training loss: 1.0454583636351995   195  0.831111341714859\n",
      "Training loss: 1.0439102521964483   196  0.838389664888382\n",
      "Training loss: 1.0404980948993139   197  0.8757392466068268\n",
      "Training loss: 1.0470564195087977   198  0.8149821758270264\n",
      "Training loss: 1.0438897524561201   199  0.8323232680559158\n",
      "Training loss: 1.044026528085981   200  0.8290875256061554\n",
      "Training loss: 1.044349993978228   201  0.8372279703617096\n",
      "Training loss: 1.0430757786546434   202  0.8239736258983612\n",
      "Training loss: 1.0329555315630776   203  0.799280971288681\n",
      "Training loss: 1.0289347767829895   204  0.8185084462165833\n",
      "Training loss: 1.0257717285837447   205  0.84049391746521\n",
      "Training loss: 1.030885589974267   206  0.8165919035673141\n",
      "Training loss: 1.0172087166990553   207  0.8215392827987671\n",
      "Training loss: 1.0130306822913033   208  0.8416789174079895\n",
      "Training loss: 1.01907246027674   209  0.802447572350502\n",
      "Training loss: 1.0103261811392648   210  0.8156759291887283\n",
      "Training loss: 1.0039100391524178   211  0.8151645064353943\n",
      "Training loss: 1.007349648645946   212  0.8452092111110687\n",
      "Training loss: 1.007879159280232   213  0.8195765912532806\n",
      "Training loss: 1.0001424295561654   214  0.801624059677124\n",
      "Training loss: 1.0004521608352661   215  0.8222621977329254\n",
      "Training loss: 1.0016289608819144   216  0.7776798456907272\n",
      "Training loss: 0.9958300122192928   217  0.7791120857000351\n",
      "Training loss: 0.9982410243579319   218  0.7948109805583954\n",
      "Training loss: 0.9969774527209145   219  0.8212256133556366\n",
      "Training loss: 0.987586783511298   220  0.7782215476036072\n",
      "Training loss: 0.993264479296548   221  0.8121240437030792\n",
      "Training loss: 0.9854153777871814   222  0.7809991836547852\n",
      "Training loss: 0.9801287991659982   223  0.7959918975830078\n",
      "Training loss: 0.9818377579961505   224  0.7947377860546112\n",
      "Training loss: 0.9862984759466988   225  0.7919254451990128\n",
      "Training loss: 0.9736524139131818   226  0.7932133674621582\n",
      "Training loss: 0.9780604371002742   227  0.8018370568752289\n",
      "Training loss: 0.9780331977776119   228  0.7997128814458847\n",
      "Training loss: 0.9722957227911267   229  0.7886679619550705\n",
      "Training loss: 0.9677082427910396   230  0.7637946009635925\n",
      "Training loss: 0.9590132747377668   231  0.7793784588575363\n",
      "Training loss: 0.9701466049466815   232  0.7592769116163254\n",
      "Training loss: 0.9618954743657794   233  0.795437216758728\n",
      "Training loss: 0.9663324100630624   234  0.7572878897190094\n",
      "Training loss: 0.9606847848211016   235  0.7702107578516006\n",
      "Training loss: 0.95966266308512   236  0.765472337603569\n",
      "Training loss: 0.95767799445561   237  0.750738188624382\n",
      "Training loss: 0.9588643014431   238  0.7572731524705887\n",
      "Training loss: 0.9590181495462146   239  0.7825448960065842\n",
      "Training loss: 0.9504050825323377   240  0.7528774440288544\n",
      "Training loss: 0.9535321508135114   241  0.7736420780420303\n",
      "Training loss: 0.9536467748028892   242  0.7532618939876556\n",
      "Training loss: 0.9468134045600891   243  0.7771528661251068\n",
      "Training loss: 0.9461641226496015   244  0.7567565441131592\n",
      "Training loss: 0.9490528575011662   245  0.7385956048965454\n",
      "Training loss: 0.9412507627691541   246  0.732539027929306\n",
      "Training loss: 0.9429005299295697   247  0.749947264790535\n",
      "Training loss: 0.938125627381461   248  0.7631150484085083\n",
      "Training loss: 0.9440522066184452   249  0.7753890305757523\n",
      "Training loss: 0.942531419651849   250  0.7545111775398254\n",
      "Training loss: 0.9407005310058594   251  0.7511464059352875\n",
      "Training loss: 0.9395610604967389   252  0.7618790566921234\n",
      "Training loss: 0.9331764365945544   253  0.7565168291330338\n",
      "Training loss: 0.9250128141471318   254  0.7280460298061371\n",
      "Training loss: 0.9291839471885136   255  0.7645538002252579\n",
      "Training loss: 0.9315452362809863   256  0.7477085888385773\n",
      "Training loss: 0.9260599740913936   257  0.7521978318691254\n",
      "Training loss: 0.9305656765188489   258  0.7614275962114334\n",
      "Training loss: 0.9259857322488513   259  0.7419122159481049\n",
      "Training loss: 0.9306500596659524   260  0.7489785254001617\n",
      "Training loss: 0.9314396594251905   261  0.7360488325357437\n",
      "Training loss: 0.9175031525748116   262  0.7397175431251526\n",
      "Training loss: 0.917565256357193   263  0.7279182076454163\n",
      "Training loss: 0.9193822869232723   264  0.748057946562767\n",
      "Training loss: 0.9270026683807373   265  0.7238784432411194\n",
      "Training loss: 0.9183868382658277   266  0.7371367961168289\n",
      "Training loss: 0.9146735795906612   267  0.7567956149578094\n",
      "Training loss: 0.9150303219045911   268  0.7271337509155273\n",
      "Training loss: 0.91881149155753   269  0.7494400143623352\n",
      "Training loss: 0.9103290821824755   270  0.7534442096948624\n",
      "Training loss: 0.904333450964519   271  0.7014444321393967\n",
      "Training loss: 0.905359319278172   272  0.7154494225978851\n",
      "Training loss: 0.9017055971281869   273  0.7067689001560211\n",
      "Training loss: 0.8926222664969308   274  0.7145048230886459\n",
      "Training loss: 0.8932444878986904   275  0.7275286614894867\n",
      "Training loss: 0.898411478315081   276  0.7351245582103729\n",
      "Training loss: 0.89242394055639   277  0.7023947387933731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.8934222374643598   278  0.7107773423194885\n",
      "Training loss: 0.8938259141785758   279  0.7081173956394196\n",
      "Training loss: 0.8967540775026593   280  0.736974224448204\n",
      "Training loss: 0.8860942891665867   281  0.7167745232582092\n",
      "Training loss: 0.8814406650406974   282  0.7172767221927643\n",
      "Training loss: 0.8802767268248967   283  0.6977091133594513\n",
      "Training loss: 0.8833547106810978   284  0.7068128734827042\n",
      "Training loss: 0.887615293264389   285  0.7052132040262222\n",
      "Training loss: 0.8881429731845856   286  0.7052008509635925\n",
      "Training loss: 0.8895553009850639   287  0.6994018256664276\n",
      "Training loss: 0.8728485448019845   288  0.6965826600790024\n",
      "Training loss: 0.8774828059332711   289  0.7184227854013443\n",
      "Training loss: 0.874030236686979   290  0.7120390981435776\n",
      "Training loss: 0.8806318087237222   291  0.6869942545890808\n",
      "Training loss: 0.8793765263898032   292  0.700560599565506\n",
      "Training loss: 0.8785394898482731   293  0.6878727227449417\n",
      "Training loss: 0.8700269290379116   294  0.7220810949802399\n",
      "Training loss: 0.8714633158275059   295  0.6990701109170914\n",
      "Training loss: 0.8713320536272866   296  0.7048407196998596\n",
      "Training loss: 0.8748798242637089   297  0.6810396313667297\n",
      "Training loss: 0.8552434146404266   298  0.6889102458953857\n",
      "Training loss: 0.862016499042511   299  0.690272331237793\n",
      "Training loss: 0.8608916018690381   300  0.6923125684261322\n",
      "Training loss: 0.8705225374017443   301  0.6944450438022614\n",
      "Training loss: 0.8778030574321747   302  0.7042069435119629\n",
      "Training loss: 0.861439266375133   303  0.6978159099817276\n",
      "Training loss: 0.849688994032996   304  0.6821248829364777\n",
      "Training loss: 0.853627622127533   305  0.6861130893230438\n",
      "Training loss: 0.8619031054633004   306  0.6634309440851212\n",
      "Training loss: 0.8540048599243164   307  0.6875386238098145\n",
      "Training loss: 0.850628422839301   308  0.6880168169736862\n",
      "Training loss: 0.8511920103005001   309  0.6731483638286591\n",
      "Training loss: 0.8525268307753971   310  0.6872038245201111\n",
      "Training loss: 0.8491435348987579   311  0.6757746040821075\n",
      "Training loss: 0.8512532498155322   312  0.6873248517513275\n",
      "Training loss: 0.8466890496867043   313  0.6567614376544952\n",
      "Training loss: 0.84541802746909   314  0.6862767934799194\n",
      "Training loss: 0.8480045071669987   315  0.6826146394014359\n",
      "Training loss: 0.8481005302497319   316  0.6753517985343933\n",
      "Training loss: 0.850964252437864   317  0.6884003281593323\n",
      "Training loss: 0.8528535195759365   318  0.6921351552009583\n",
      "Training loss: 0.8495835491589138   319  0.6599458158016205\n",
      "Training loss: 0.8422640264034271   320  0.6555654257535934\n",
      "Training loss: 0.8426081623349871   321  0.6663233488798141\n",
      "Training loss: 0.8413813327039991   322  0.6839386969804764\n",
      "Training loss: 0.838004972253527   323  0.6674924939870834\n",
      "Training loss: 0.8432898989745549   324  0.6719857305288315\n",
      "Training loss: 0.8342509823186057   325  0.6680817008018494\n",
      "Training loss: 0.8382216266223362   326  0.6787352114915848\n",
      "Training loss: 0.830845309155328   327  0.6685295701026917\n",
      "Training loss: 0.8214447966643742   328  0.6623056977987289\n",
      "Training loss: 0.8319130667618343   329  0.6803889870643616\n",
      "Training loss: 0.8299969264439174   330  0.6645547747612\n",
      "Training loss: 0.8250105721609933   331  0.6685088872909546\n",
      "Training loss: 0.8317784156118121   332  0.6672506779432297\n",
      "Training loss: 0.8352181187697819   333  0.6707168817520142\n",
      "Training loss: 0.8319267162254879   334  0.6684455871582031\n",
      "Training loss: 0.8300523502486092   335  0.672399640083313\n",
      "Training loss: 0.8370409437588283   336  0.6560341119766235\n",
      "Training loss: 0.8316329632486615   337  0.6463546901941299\n",
      "Training loss: 0.8261565566062927   338  0.667230099439621\n",
      "Training loss: 0.8225450473172324   339  0.6595498025417328\n",
      "Training loss: 0.8223512257848468   340  0.6406587213277817\n",
      "Training loss: 0.8195074370929173   341  0.6353750973939896\n",
      "Training loss: 0.8149734011718205   342  0.6625121831893921\n",
      "Training loss: 0.8108986829008374   343  0.6376282572746277\n",
      "Training loss: 0.8038391854081836   344  0.6581770479679108\n",
      "Training loss: 0.806025607245309   345  0.660532146692276\n",
      "Training loss: 0.806304178067616   346  0.6448612660169601\n",
      "Training loss: 0.8077474747385297   347  0.641942098736763\n",
      "Training loss: 0.8058285670621055   348  0.6449991762638092\n",
      "Training loss: 0.8149236440658569   349  0.6416286081075668\n",
      "Training loss: 0.8095124193600246   350  0.6358182579278946\n",
      "Training loss: 0.8157878773553031   351  0.6405451744794846\n",
      "Training loss: 0.826754846743175   352  0.6592445075511932\n",
      "Training loss: 0.8046878789152417   353  0.6319281458854675\n",
      "Training loss: 0.8058303722313472   354  0.6416173130273819\n",
      "Training loss: 0.7981083903993879   355  0.6642729043960571\n",
      "Training loss: 0.8033229964120048   356  0.634581059217453\n",
      "Training loss: 0.8032338065760476   357  0.6454481929540634\n",
      "Training loss: 0.8014875309807914   358  0.6513732671737671\n",
      "Training loss: 0.8025146722793579   359  0.6406446993350983\n",
      "Training loss: 0.7984315838132586   360  0.6240207254886627\n",
      "Training loss: 0.7952813761574882   361  0.6567703187465668\n",
      "Training loss: 0.8089066318103245   362  0.6442516893148422\n",
      "Training loss: 0.8050219586917332   363  0.6495559811592102\n",
      "Training loss: 0.7934777310916356   364  0.6501849293708801\n",
      "Training loss: 0.7966842012745994   365  0.6455041468143463\n",
      "Training loss: 0.7940099154199872   366  0.6350673288106918\n",
      "Training loss: 0.7875346030507769   367  0.6435501277446747\n",
      "Training loss: 0.7893478700092861   368  0.6234579980373383\n",
      "Training loss: 0.7837966467653003   369  0.6092302054166794\n",
      "Training loss: 0.7909084856510162   370  0.6177539825439453\n",
      "Training loss: 0.7855920621326992   371  0.6111859977245331\n",
      "Training loss: 0.7825677522591182   372  0.6146692782640457\n",
      "Training loss: 0.7932996026107243   373  0.6308751106262207\n",
      "Training loss: 0.7871094729219165   374  0.6429804861545563\n",
      "Training loss: 0.7864915941442762   375  0.6297047585248947\n",
      "Training loss: 0.7825010206018176   376  0.6196471899747849\n",
      "Training loss: 0.7789363052163806   377  0.6139766871929169\n",
      "Training loss: 0.7772939928940364   378  0.6181903332471848\n",
      "Training loss: 0.7760041356086731   379  0.6313412934541702\n",
      "Training loss: 0.7752877218382699   380  0.6025825291872025\n",
      "Training loss: 0.7767844455582755   381  0.6359899044036865\n",
      "Training loss: 0.7776199323790414   382  0.6222134381532669\n",
      "Training loss: 0.7810479232243129   383  0.6455021649599075\n",
      "Training loss: 0.7760908859116691   384  0.6211785823106766\n",
      "Training loss: 0.7723132584776197   385  0.6218547374010086\n",
      "Training loss: 0.7702888548374176   386  0.6166377067565918\n",
      "Training loss: 0.7782220670155117   387  0.61665178835392\n",
      "Training loss: 0.7776770634310586   388  0.6156304478645325\n",
      "Training loss: 0.7722668605191367   389  0.6332141309976578\n",
      "Training loss: 0.7745180257729122   390  0.6351761370897293\n",
      "Training loss: 0.7679069723401751   391  0.6120366007089615\n",
      "Training loss: 0.7622252021517072   392  0.6203583776950836\n",
      "Training loss: 0.7688519997256142   393  0.6078706234693527\n",
      "Training loss: 0.7594217870916639   394  0.6070786416530609\n",
      "Training loss: 0.7614049868924277   395  0.6051284223794937\n",
      "Training loss: 0.7610848844051361   396  0.6217209696769714\n",
      "Training loss: 0.7626011329037803   397  0.6184080988168716\n",
      "Training loss: 0.7664666133267539   398  0.597992941737175\n",
      "Training loss: 0.7616213006632668   399  0.619933545589447\n",
      "Training loss: 0.7582828828266689   400  0.6235963851213455\n",
      "Training loss: 0.7577428902898516   401  0.6011362373828888\n",
      "Training loss: 0.7604575072016034   402  0.599030464887619\n",
      "Training loss: 0.7572821719305856   403  0.605513721704483\n",
      "Training loss: 0.7522348633834294   404  0.6137163043022156\n",
      "Training loss: 0.7513303501265389   405  0.59825499355793\n",
      "Training loss: 0.7532758499894824   406  0.6076063811779022\n",
      "Training loss: 0.7535741244043622   407  0.6077731996774673\n",
      "Training loss: 0.7507939466408321   408  0.5962798744440079\n",
      "Training loss: 0.7562013651643481   409  0.6097624748945236\n",
      "Training loss: 0.7505476091589246   410  0.6034524738788605\n",
      "Training loss: 0.7466533439499992   411  0.5996109545230865\n",
      "Training loss: 0.7484218222754342   412  0.6217313259840012\n",
      "Training loss: 0.7553125364439828   413  0.5915701389312744\n",
      "Training loss: 0.7597208448818752   414  0.6025622487068176\n",
      "Training loss: 0.7500164253371102   415  0.5811691731214523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.7479022783892495   416  0.6055284738540649\n",
      "Training loss: 0.7457504655633654   417  0.6022209972143173\n",
      "Training loss: 0.7504739378179822   418  0.6153638511896133\n",
      "Training loss: 0.7595745367663247   419  0.595868855714798\n",
      "Training loss: 0.7502173100199018   420  0.6071660071611404\n",
      "Training loss: 0.7576921241624015   421  0.6026327461004257\n",
      "Training loss: 0.7514404441629138   422  0.5999505370855331\n",
      "Training loss: 0.7506821538720813   423  0.5967507511377335\n",
      "Training loss: 0.7442044786044529   424  0.6155674457550049\n",
      "Training loss: 0.7398228475025722   425  0.5882350206375122\n",
      "Training loss: 0.7398256531783513   426  0.603010892868042\n",
      "Training loss: 0.7386456685406821   427  0.5985923707485199\n",
      "Training loss: 0.7440601416996547   428  0.6086777895689011\n",
      "Training loss: 0.7433668502739498   429  0.5860339552164078\n",
      "Training loss: 0.735123119183949   430  0.5897344201803207\n",
      "Training loss: 0.737074979713985   431  0.5921019911766052\n",
      "Training loss: 0.7395054272242955   432  0.584706500172615\n",
      "Training loss: 0.7394334546157292   433  0.5987754613161087\n",
      "Training loss: 0.7323504303182874   434  0.6006666570901871\n",
      "Training loss: 0.7370079713208335   435  0.5961717218160629\n",
      "Training loss: 0.7371349717889514   436  0.578822910785675\n",
      "Training loss: 0.7338979712554387   437  0.5840858966112137\n",
      "Training loss: 0.7345009871891567   438  0.6040984094142914\n",
      "Training loss: 0.7414116518838065   439  0.5885893851518631\n",
      "Training loss: 0.7407337597438267   440  0.5916251242160797\n",
      "Training loss: 0.7283869981765747   441  0.5783095359802246\n",
      "Training loss: 0.7307389421122414   442  0.5835223942995071\n",
      "Training loss: 0.7327230104378292   443  0.5814377665519714\n",
      "Training loss: 0.725291337285723   444  0.5991581082344055\n",
      "Training loss: 0.7291044976030078   445  0.5850483924150467\n",
      "Training loss: 0.727816002709525   446  0.5836762487888336\n",
      "Training loss: 0.7248942809445518   447  0.5988080948591232\n",
      "Training loss: 0.7422270008495876   448  0.5976818799972534\n",
      "Training loss: 0.7312876454421452   449  0.5851350128650665\n",
      "Training loss: 0.7306916798864093   450  0.5916087329387665\n",
      "Training loss: 0.7312605679035187   451  0.566089317202568\n",
      "Training loss: 0.722358409847532   452  0.5824848860502243\n",
      "Training loss: 0.7223332524299622   453  0.582891047000885\n",
      "Training loss: 0.7269075342587062   454  0.5746600329875946\n",
      "Training loss: 0.7228241562843323   455  0.5785067975521088\n",
      "Training loss: 0.721780925989151   456  0.5975996553897858\n",
      "Training loss: 0.7251158143792834   457  0.5786987841129303\n",
      "Training loss: 0.7235459727900369   458  0.5751134902238846\n",
      "Training loss: 0.7158921190670559   459  0.5832134187221527\n",
      "Training loss: 0.7227065776075635   460  0.5711676180362701\n",
      "Training loss: 0.7215966411999294   461  0.5832895636558533\n",
      "Training loss: 0.7188016814844949   462  0.5840163975954056\n",
      "Training loss: 0.7219731594835009   463  0.579033613204956\n",
      "Training loss: 0.7218152710369655   464  0.5866235494613647\n",
      "Training loss: 0.7233295312949589   465  0.5525148063898087\n",
      "Training loss: 0.7186106102807182   466  0.5737053602933884\n",
      "Training loss: 0.7158872485160828   467  0.5847810208797455\n",
      "Training loss: 0.713356362921851   468  0.5719007104635239\n",
      "Training loss: 0.7137351163796016   469  0.5698560178279877\n",
      "Training loss: 0.7109640794140952   470  0.5698267370462418\n",
      "Training loss: 0.7117786577769688   471  0.6000180840492249\n",
      "Training loss: 0.7179271493639264   472  0.5914893299341202\n",
      "Training loss: 0.7123991250991821   473  0.5788457244634628\n",
      "Training loss: 0.7172401206833976   474  0.5608603209257126\n",
      "Training loss: 0.7123269353594098   475  0.5723416358232498\n",
      "Training loss: 0.7107273723397937   476  0.5682028532028198\n",
      "Training loss: 0.7096190324851445   477  0.5732627958059311\n",
      "Training loss: 0.7126922011375427   478  0.576344221830368\n",
      "Training loss: 0.7153489547116416   479  0.565729558467865\n",
      "Training loss: 0.7120034056050437   480  0.5767578035593033\n",
      "Training loss: 0.7125635189669473   481  0.5621264576911926\n",
      "Training loss: 0.7052479003156934   482  0.5712209492921829\n",
      "Training loss: 0.7060792062963758   483  0.5736772269010544\n",
      "Training loss: 0.7113797664642334   484  0.5806818753480911\n",
      "Training loss: 0.6989573453153882   485  0.5760070532560349\n",
      "Training loss: 0.6989693428788867   486  0.553078755736351\n",
      "Training loss: 0.7052024900913239   487  0.5741367489099503\n",
      "Training loss: 0.7083949318953923   488  0.5625449568033218\n",
      "Training loss: 0.7070366867950985   489  0.5596366822719574\n",
      "Training loss: 0.7070524394512177   490  0.5715362876653671\n",
      "Training loss: 0.7041229818548475   491  0.5770707130432129\n",
      "Training loss: 0.7003205418586731   492  0.5660391002893448\n",
      "Training loss: 0.7048096827098301   493  0.588362380862236\n",
      "Training loss: 0.7135153540543148   494  0.5540408194065094\n",
      "Training loss: 0.7058227913720267   495  0.5766691714525223\n",
      "Training loss: 0.7008119523525238   496  0.5849933326244354\n",
      "Training loss: 0.7024183741637638   497  0.5687029957771301\n",
      "Training loss: 0.7017555705138615   498  0.544953003525734\n",
      "Training loss: 0.6979082780224937   499  0.5635818541049957\n",
      "Training loss: 0.6996981884752002   500  0.5592566281557083\n",
      "Training loss: 0.6998704416411263   501  0.5591440051794052\n",
      "Training loss: 0.7019898678575244   502  0.5662849992513657\n",
      "Training loss: 0.7038430230958121   503  0.5777455568313599\n",
      "Training loss: 0.6968879955155509   504  0.5537676215171814\n",
      "Training loss: 0.695129781961441   505  0.570410817861557\n",
      "Training loss: 0.6969697177410126   506  0.5534335672855377\n",
      "Training loss: 0.700615005833762   507  0.563100665807724\n",
      "Training loss: 0.6971529849937984   508  0.5603867769241333\n",
      "Training loss: 0.6894752340657371   509  0.5496482402086258\n",
      "Training loss: 0.6966938674449921   510  0.5759070515632629\n",
      "Training loss: 0.6967481970787048   511  0.5732233077287674\n",
      "Training loss: 0.698574538741793   512  0.5579832941293716\n",
      "Training loss: 0.6998131402901241   513  0.5482083559036255\n",
      "Training loss: 0.6950451391083854   514  0.5536504536867142\n",
      "Training loss: 0.6941056847572327   515  0.5681068748235703\n",
      "Training loss: 0.6968102157115936   516  0.5567704737186432\n",
      "Training loss: 0.694396334035056   517  0.5534911304712296\n",
      "Training loss: 0.6887549672807965   518  0.5548577457666397\n",
      "Training loss: 0.7030062207153865   519  0.5458774268627167\n",
      "Training loss: 0.6882765420845577   520  0.5426820814609528\n",
      "Training loss: 0.6967936456203461   521  0.5616266429424286\n",
      "Training loss: 0.6900052598544529   522  0.5563677400350571\n",
      "Training loss: 0.6857631717409406   523  0.5581363141536713\n",
      "Training loss: 0.6894360482692719   524  0.5721826255321503\n",
      "Training loss: 0.6923757067748478   525  0.5490966290235519\n",
      "Training loss: 0.6899780077593667   526  0.5488160699605942\n",
      "Training loss: 0.6896416374615261   527  0.5714301317930222\n",
      "Training loss: 0.6884489740644183   528  0.5522786527872086\n",
      "Training loss: 0.6853686145373753   529  0.5420038551092148\n",
      "Training loss: 0.6947518501962934   530  0.5667553395032883\n",
      "Training loss: 0.693634067262922   531  0.5439022332429886\n",
      "Training loss: 0.6777990758419037   532  0.5425924360752106\n",
      "Training loss: 0.6860662996768951   533  0.5476366281509399\n",
      "Training loss: 0.6775631393705096   534  0.5510752499103546\n",
      "Training loss: 0.6833740557943072   535  0.5613503009080887\n",
      "Training loss: 0.6808896277632032   536  0.5503197908401489\n",
      "Training loss: 0.6899803834302085   537  0.5557016581296921\n",
      "Training loss: 0.6835857672350747   538  0.5449290871620178\n",
      "Training loss: 0.6860902607440948   539  0.5506724268198013\n",
      "Training loss: 0.6781371831893921   540  0.5420110821723938\n",
      "Training loss: 0.6818556615284511   541  0.5505067706108093\n",
      "Training loss: 0.6746558674744197   542  0.5494451224803925\n",
      "Training loss: 0.6796969643660954   543  0.5381840020418167\n",
      "Training loss: 0.6765822512762887   544  0.5577007532119751\n",
      "Training loss: 0.6824000797101429   545  0.5434343218803406\n",
      "Training loss: 0.68480184674263   546  0.5312266945838928\n",
      "Training loss: 0.67886997120721   547  0.5382571965456009\n",
      "Training loss: 0.6828764847346714   548  0.5555523186922073\n",
      "Training loss: 0.6802059667451041   549  0.5483932942152023\n",
      "Training loss: 0.6800404574189868   550  0.5488308370113373\n",
      "Training loss: 0.6796367721898215   551  0.5635127276182175\n",
      "Training loss: 0.6751257266317096   552  0.5500124394893646\n",
      "Training loss: 0.6761758242334638   553  0.5336045175790787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.6768895089626312   554  0.55685955286026\n",
      "Training loss: 0.6814416774681636   555  0.559089258313179\n",
      "Training loss: 0.6778334294046674   556  0.5459938198328018\n",
      "Training loss: 0.6786941800798688   557  0.5314177572727203\n",
      "Training loss: 0.6731986999511719   558  0.5556741058826447\n",
      "Training loss: 0.6813970804214478   559  0.542524591088295\n",
      "Training loss: 0.6773644089698792   560  0.5424317419528961\n",
      "Training loss: 0.67432787162917   561  0.5344730913639069\n",
      "Training loss: 0.6705750823020935   562  0.55775386095047\n",
      "Training loss: 0.6747985482215881   563  0.5492940247058868\n",
      "Training loss: 0.6777212449482509   564  0.5485763102769852\n",
      "Training loss: 0.6735041396958488   565  0.5470851808786392\n",
      "Training loss: 0.676072073834283   566  0.5428361296653748\n",
      "Training loss: 0.67743091072355   567  0.5423199981451035\n",
      "Training loss: 0.6751563421317509   568  0.5576214790344238\n",
      "Training loss: 0.6701193026133946   569  0.5399528741836548\n",
      "Training loss: 0.6717980120863233   570  0.543396845459938\n",
      "Training loss: 0.6689435158457074   571  0.543625608086586\n",
      "Training loss: 0.6719784651483808   572  0.535486027598381\n",
      "Training loss: 0.6748468364988055   573  0.5484912544488907\n",
      "Training loss: 0.6740452987807137   574  0.5337375402450562\n",
      "Training loss: 0.6741359276430947   575  0.5410084426403046\n",
      "Training loss: 0.6693909551416125   576  0.5295751541852951\n",
      "Training loss: 0.672517899956022   577  0.5520022362470627\n",
      "Training loss: 0.6643201581069401   578  0.5271622389554977\n",
      "Training loss: 0.6665915974548885   579  0.5189539790153503\n",
      "Training loss: 0.6614754285131182   580  0.5358726382255554\n",
      "Training loss: 0.6670612011637006   581  0.5270120799541473\n",
      "Training loss: 0.6663539963109153   582  0.5326022803783417\n",
      "Training loss: 0.6703623575823647   583  0.5346481502056122\n",
      "Training loss: 0.6698950358799526   584  0.5514928251504898\n",
      "Training loss: 0.6657000439507621   585  0.5364008247852325\n",
      "Training loss: 0.6629894886698041   586  0.5334620624780655\n",
      "Training loss: 0.6669952571392059   587  0.5376440584659576\n",
      "Training loss: 0.669594155890601   588  0.5431036949157715\n",
      "Training loss: 0.6643992108958108   589  0.542452335357666\n",
      "Training loss: 0.6667565362794059   590  0.5363175421953201\n",
      "Training loss: 0.6695686663900103   591  0.5090901404619217\n",
      "Training loss: 0.6632707629884992   592  0.5102784782648087\n",
      "Training loss: 0.6658901274204254   593  0.5410611629486084\n",
      "Training loss: 0.6649499791009086   594  0.528799295425415\n",
      "Training loss: 0.6601971728461129   595  0.5394592583179474\n",
      "Training loss: 0.6568313155855451   596  0.5235456824302673\n",
      "Training loss: 0.6651301256247929   597  0.5343612879514694\n",
      "Training loss: 0.6689229777881077   598  0.5302803665399551\n",
      "Training loss: 0.670191786118916   599  0.5377011746168137\n",
      "Training loss: 0.6695002572877067   600  0.5435758382081985\n",
      "Training loss: 0.6614201366901398   601  0.541054978966713\n",
      "Training loss: 0.6614261993340084   602  0.5288356989622116\n",
      "Training loss: 0.6622342382158551   603  0.5312000513076782\n",
      "Training loss: 0.6628667116165161   604  0.5415165722370148\n",
      "Training loss: 0.6697115812982831   605  0.5189763009548187\n",
      "Training loss: 0.6622271154608045   606  0.5407253354787827\n",
      "Training loss: 0.6582703930991036   607  0.5380283892154694\n",
      "Training loss: 0.6623258207525525   608  0.529365062713623\n",
      "Training loss: 0.6677379480430058   609  0.5427779108285904\n",
      "Training loss: 0.6655030378273555   610  0.5259484797716141\n",
      "Training loss: 0.6598515510559082   611  0.5384238213300705\n",
      "Training loss: 0.6645008027553558   612  0.5446154177188873\n",
      "Training loss: 0.659954696893692   613  0.5343044847249985\n",
      "Training loss: 0.6612819944109235   614  0.5370004773139954\n",
      "Training loss: 0.658194397177015   615  0.5216045379638672\n",
      "Training loss: 0.6616131833621434   616  0.529663696885109\n",
      "Training loss: 0.658851832151413   617  0.5252730548381805\n",
      "Training loss: 0.655705179486956   618  0.5409726798534393\n",
      "Training loss: 0.6622833907604218   619  0.52286696434021\n",
      "Training loss: 0.667094920362745   620  0.5315406918525696\n",
      "Training loss: 0.6557515135833195   621  0.5154638290405273\n",
      "Training loss: 0.6558390770639692   622  0.522512823343277\n",
      "Training loss: 0.6521095548357282   623  0.5337265580892563\n",
      "Training loss: 0.6564536137240273   624  0.5320320427417755\n",
      "Training loss: 0.6586006730794907   625  0.5348942875862122\n",
      "Training loss: 0.6543778351375035   626  0.5240408927202225\n",
      "Training loss: 0.6508352075304303   627  0.518288865685463\n",
      "Training loss: 0.651066107409341   628  0.5120583325624466\n",
      "Training loss: 0.6566253134182521   629  0.5460558831691742\n",
      "Training loss: 0.6588158224310193   630  0.5239794105291367\n",
      "Training loss: 0.6539039058344704   631  0.5306150913238525\n",
      "Training loss: 0.6541001754147666   632  0.5281123518943787\n",
      "Training loss: 0.655348892722811   633  0.5190330892801285\n",
      "Training loss: 0.6559504568576813   634  0.5214911848306656\n",
      "Training loss: 0.6535121159894126   635  0.5339384227991104\n",
      "Training loss: 0.6563225814274379   636  0.5219839066267014\n",
      "Training loss: 0.6574085227080754   637  0.5181682258844376\n",
      "Training loss: 0.6546274508748736   638  0.5184313803911209\n",
      "Training loss: 0.6677344739437103   639  0.5543182790279388\n",
      "Training loss: 0.6785263248852321   640  0.5363962352275848\n",
      "Training loss: 0.6606899542467934   641  0.5227944701910019\n",
      "Training loss: 0.6533429282052177   642  0.5199180543422699\n",
      "Training loss: 0.651390573808125   643  0.5182528793811798\n",
      "Training loss: 0.6521543945584979   644  0.5130308270454407\n",
      "Training loss: 0.6518589173044477   645  0.5189711898565292\n",
      "Training loss: 0.6490432151726314   646  0.5304251313209534\n",
      "Training loss: 0.6518820439066205   647  0.5382703989744186\n",
      "Training loss: 0.6532383859157562   648  0.5258253812789917\n",
      "Training loss: 0.6544266981737954   649  0.5285227298736572\n",
      "Training loss: 0.6472816041537693   650  0.5367394238710403\n",
      "Training loss: 0.6497132650443486   651  0.5251084864139557\n",
      "Training loss: 0.6488501557282039   652  0.5165973603725433\n",
      "Training loss: 0.6459447486060006   653  0.5104796886444092\n",
      "Training loss: 0.65058405484472   654  0.5123688876628876\n",
      "Training loss: 0.6524221343653542   655  0.5227808356285095\n",
      "Training loss: 0.6486921352999551   656  0.5282782912254333\n",
      "Training loss: 0.6452115816729409   657  0.5299540460109711\n",
      "Training loss: 0.6521421883787427   658  0.5223283022642136\n",
      "Training loss: 0.650338100535529   659  0.5222909599542618\n",
      "Training loss: 0.6483825402600425   660  0.5218637734651566\n",
      "Training loss: 0.6437213250568935   661  0.5159090608358383\n",
      "Training loss: 0.6511213992323194   662  0.5123417377471924\n",
      "Training loss: 0.6421851856367928   663  0.5214780420064926\n",
      "Training loss: 0.6439661085605621   664  0.5233280509710312\n",
      "Training loss: 0.6449138649872371   665  0.5287458449602127\n",
      "Training loss: 0.6444444486073085   666  0.5196854621171951\n",
      "Training loss: 0.6456601960318429   667  0.5046190321445465\n",
      "Training loss: 0.6452439895698002   668  0.5133575946092606\n",
      "Training loss: 0.646812664610999   669  0.5108250826597214\n",
      "Training loss: 0.6391645627362388   670  0.5248033702373505\n",
      "Training loss: 0.6462792413575309   671  0.5168386548757553\n",
      "Training loss: 0.646972975560597   672  0.5207892060279846\n",
      "Training loss: 0.6494096176964896   673  0.5263627916574478\n",
      "Training loss: 0.6427447540419442   674  0.5041122287511826\n",
      "Training loss: 0.6485077781336648   675  0.5199785828590393\n",
      "Training loss: 0.6438488193920681   676  0.5336562693119049\n",
      "Training loss: 0.6475632233279092   677  0.5269259810447693\n",
      "Training loss: 0.6421357435839516   678  0.5227346420288086\n",
      "Training loss: 0.6460357138088771   679  0.5099966078996658\n",
      "Training loss: 0.6372765856129783   680  0.5208060890436172\n",
      "Training loss: 0.6447755183492389   681  0.5138275623321533\n",
      "Training loss: 0.6455663102013725   682  0.5340331196784973\n",
      "Training loss: 0.6432148516178131   683  0.5144653022289276\n",
      "Training loss: 0.6446015919957843   684  0.5118960589170456\n",
      "Training loss: 0.64495878134455   685  0.5128350406885147\n",
      "Training loss: 0.6450915890080589   686  0.5141064375638962\n",
      "Training loss: 0.6468373196465629   687  0.5190199315547943\n",
      "Training loss: 0.6401626084532056   688  0.5080534368753433\n",
      "Training loss: 0.6406292617321014   689  0.5280063599348068\n",
      "Training loss: 0.6430667127881732   690  0.502144455909729\n",
      "Training loss: 0.6400717113699231   691  0.5220719277858734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.6426644495555333   692  0.5161322057247162\n",
      "Training loss: 0.6396797299385071   693  0.5080975741147995\n",
      "Training loss: 0.6433480041367667   694  0.5186445862054825\n",
      "Training loss: 0.6357501191752297   695  0.49964265525341034\n",
      "Training loss: 0.6383837504046304   696  0.5081293433904648\n",
      "Training loss: 0.643045791557857   697  0.5056715458631516\n",
      "Training loss: 0.6361167643751416   698  0.5159727483987808\n",
      "Training loss: 0.6440700888633728   699  0.5052224397659302\n",
      "Training loss: 0.6411022458757673   700  0.5237567275762558\n",
      "Training loss: 0.6375585879598346   701  0.5101628303527832\n",
      "Training loss: 0.6376448912279946   702  0.532913401722908\n",
      "Training loss: 0.6456432555403028   703  0.5167058855295181\n",
      "Training loss: 0.637549911226545   704  0.5091809779405594\n",
      "Training loss: 0.6376132837363652   705  0.5083639472723007\n",
      "Training loss: 0.6391345475401197   706  0.5225495845079422\n",
      "Training loss: 0.6403040077005114   707  0.5138257145881653\n",
      "Training loss: 0.6401902607509068   708  0.5053050369024277\n",
      "Training loss: 0.6382200334753309   709  0.5196428298950195\n",
      "Training loss: 0.6407888829708099   710  0.5094528794288635\n",
      "Training loss: 0.6359129505498069   711  0.5125904828310013\n",
      "Training loss: 0.6393003208296639   712  0.51921147108078\n",
      "Training loss: 0.6333432112421308   713  0.5303628742694855\n",
      "Training loss: 0.6397392111165183   714  0.5176452845335007\n",
      "Training loss: 0.6335800247532981   715  0.49995550513267517\n",
      "Training loss: 0.6361313249383654   716  0.5013832151889801\n",
      "Training loss: 0.638609881911959   717  0.5143915265798569\n",
      "Training loss: 0.633709796837398   718  0.5128908008337021\n",
      "Training loss: 0.6345506310462952   719  0.5272474586963654\n",
      "Training loss: 0.6368630741323743   720  0.5143751800060272\n",
      "Training loss: 0.6397303768566677   721  0.5251274406909943\n",
      "Training loss: 0.6333494356700352   722  0.5060130506753922\n",
      "Training loss: 0.6406998378889901   723  0.5077551752328873\n",
      "Training loss: 0.6314929894038609   724  0.500580757856369\n",
      "Training loss: 0.6356014694486346   725  0.4940238744020462\n",
      "Training loss: 0.6356684565544128   726  0.5144064724445343\n",
      "Training loss: 0.6338424342019218   727  0.5174770057201385\n",
      "Training loss: 0.6293856544154031   728  0.5115793645381927\n",
      "Training loss: 0.6387848045144763   729  0.5111371725797653\n",
      "Training loss: 0.6422259083815983   730  0.5255053788423538\n",
      "Training loss: 0.6428325729710715   731  0.5202018469572067\n",
      "Training loss: 0.6355016444410596   732  0.5190741270780563\n",
      "Training loss: 0.6352598581995282   733  0.49603740870952606\n",
      "Training loss: 0.6368444689682552   734  0.5047794878482819\n",
      "Training loss: 0.6317367425986699   735  0.5069571435451508\n",
      "Training loss: 0.6369407219546181   736  0.5000931620597839\n",
      "Training loss: 0.6343940411295209   737  0.5098155587911606\n",
      "Training loss: 0.6303984352520534   738  0.5023806542158127\n",
      "Training loss: 0.6292136354105813   739  0.502546638250351\n",
      "Training loss: 0.6348335274628231   740  0.5095203220844269\n",
      "Training loss: 0.6385900931698936   741  0.5276614129543304\n",
      "Training loss: 0.6390895034585681   742  0.5067343860864639\n",
      "Training loss: 0.6339826583862305   743  0.5019170939922333\n",
      "Training loss: 0.6359917734350476   744  0.5092275589704514\n",
      "Training loss: 0.628774459872927   745  0.5248933583498001\n",
      "Training loss: 0.632560521364212   746  0.4990132004022598\n",
      "Training loss: 0.632405413048608   747  0.50937619805336\n",
      "Training loss: 0.6314595980303628   748  0.5054188817739487\n",
      "Training loss: 0.6370831259659359   749  0.5155456066131592\n",
      "Training loss: 0.6321256756782532   750  0.5101268738508224\n",
      "Training loss: 0.6338453590869904   751  0.5105033367872238\n",
      "Training loss: 0.6312919429370335   752  0.5178802609443665\n",
      "Training loss: 0.6319482752255031   753  0.5115221291780472\n",
      "Training loss: 0.6268680265971592   754  0.5288795381784439\n",
      "Training loss: 0.6300065474850791   755  0.48240675032138824\n",
      "Training loss: 0.6301823939595904   756  0.5105374902486801\n",
      "Training loss: 0.6279761152608054   757  0.5061125755310059\n",
      "Training loss: 0.632776038987296   758  0.5199244916439056\n",
      "Training loss: 0.6335585287639073   759  0.5062662214040756\n",
      "Training loss: 0.6298394841807229   760  0.5024555623531342\n",
      "Training loss: 0.6312566995620728   761  0.49129094183444977\n",
      "Training loss: 0.6278110487120492   762  0.5026825070381165\n",
      "Training loss: 0.6199036410876683   763  0.4963921755552292\n",
      "Training loss: 0.6216051323073251   764  0.49941524863243103\n",
      "Training loss: 0.6243079815592084   765  0.4935358464717865\n",
      "Training loss: 0.6198267468384334   766  0.5002264082431793\n",
      "Training loss: 0.6213934293815068   767  0.49585913121700287\n",
      "Training loss: 0.6254795747143882   768  0.5066748261451721\n",
      "Training loss: 0.6231538866247449   769  0.49344414472579956\n",
      "Training loss: 0.6245066906724658   770  0.5045014768838882\n",
      "Training loss: 0.6210277889456067   771  0.49712124466896057\n",
      "Training loss: 0.6256067710263389   772  0.5209299921989441\n",
      "Training loss: 0.6293552006993975   773  0.4883280247449875\n",
      "Training loss: 0.6264906099864415   774  0.5098119080066681\n",
      "Training loss: 0.6183814321245465   775  0.5117723494768143\n",
      "Training loss: 0.6253139291490827   776  0.5075094103813171\n",
      "Training loss: 0.6249276059014457   777  0.5069049149751663\n",
      "Training loss: 0.6252543245043073   778  0.493958055973053\n",
      "Training loss: 0.6202424211161477   779  0.5018904060125351\n",
      "Training loss: 0.6244115318570819   780  0.5097927898168564\n",
      "Training loss: 0.6198529132774898   781  0.5106445848941803\n",
      "Training loss: 0.6265285398278918   782  0.5038955211639404\n",
      "Training loss: 0.622450956276485   783  0.5043087303638458\n",
      "Training loss: 0.6245393327304295   784  0.5029363483190536\n",
      "Training loss: 0.6198525428771973   785  0.5138145536184311\n",
      "Training loss: 0.6251549550465175   786  0.49508947134017944\n",
      "Training loss: 0.6186201231820243   787  0.503410816192627\n",
      "Training loss: 0.6209454621587481   788  0.4916944354772568\n",
      "Training loss: 0.6250788612025124   789  0.49703846871852875\n",
      "Training loss: 0.6182373464107513   790  0.4921751469373703\n",
      "Training loss: 0.6208358577319554   791  0.49989937245845795\n",
      "Training loss: 0.6210146929536547   792  0.4993146061897278\n",
      "Training loss: 0.6231436090809959   793  0.4920954704284668\n",
      "Training loss: 0.6187489458492824   794  0.4987918883562088\n",
      "Training loss: 0.6219840092318398   795  0.5098015666007996\n",
      "Training loss: 0.6212102132184165   796  0.5069288164377213\n",
      "Training loss: 0.6204531235354287   797  0.5097827464342117\n",
      "Training loss: 0.6223485810416085   798  0.5174219608306885\n",
      "Training loss: 0.61958190373012   799  0.5157232284545898\n",
      "Training loss: 0.6207746820790427   800  0.493549183011055\n",
      "Training loss: 0.6168523005076817   801  0.5080996304750443\n",
      "Training loss: 0.615665363413947   802  0.5059232860803604\n",
      "Training loss: 0.6151390927178519   803  0.49744752049446106\n",
      "Training loss: 0.6162973046302795   804  0.49183671176433563\n",
      "Training loss: 0.6226520325456347   805  0.49042531847953796\n",
      "Training loss: 0.6216712466308049   806  0.4888278543949127\n",
      "Training loss: 0.6186576655932835   807  0.5094395726919174\n",
      "Training loss: 0.6189117133617401   808  0.4947933256626129\n",
      "Training loss: 0.6156752237251827   809  0.49671757221221924\n",
      "Training loss: 0.619204682963235   810  0.4900829344987869\n",
      "Training loss: 0.6130494432789939   811  0.4947994500398636\n",
      "Training loss: 0.6171684052262988   812  0.5041604787111282\n",
      "Training loss: 0.6169968289988381   813  0.5007316917181015\n",
      "Training loss: 0.6183408158166068   814  0.4854774922132492\n",
      "Training loss: 0.6142206575189318   815  0.49119339883327484\n",
      "Training loss: 0.6211923616273063   816  0.505404606461525\n",
      "Training loss: 0.6202792653015682   817  0.483662948012352\n",
      "Training loss: 0.6190864103181022   818  0.5086761116981506\n",
      "Training loss: 0.6210119809423175   819  0.48038144409656525\n",
      "Training loss: 0.6226620503834316   820  0.4962224215269089\n",
      "Training loss: 0.6171384155750275   821  0.4829026609659195\n",
      "Training loss: 0.6184234278542655   822  0.4878254383802414\n",
      "Training loss: 0.6131806799343654   823  0.4991952031850815\n",
      "Training loss: 0.6176843770912716   824  0.4907641112804413\n",
      "Training loss: 0.6146117235933032   825  0.4968276768922806\n",
      "Training loss: 0.6155122305665698   826  0.5002853572368622\n",
      "Training loss: 0.6143685621874673   827  0.4934282600879669\n",
      "Training loss: 0.6202968146119799   828  0.5050519406795502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.613436051777431   829  0.5025003254413605\n",
      "Training loss: 0.616741955280304   830  0.4904544800519943\n",
      "Training loss: 0.6184714990002769   831  0.5064988881349564\n",
      "Training loss: 0.6156373023986816   832  0.5022376626729965\n",
      "Training loss: 0.6184071855885642   833  0.5053917169570923\n",
      "Training loss: 0.6175854972430638   834  0.4985700249671936\n",
      "Training loss: 0.6149134465626308   835  0.4997970014810562\n",
      "Training loss: 0.6169468419892448   836  0.48733361065387726\n",
      "Training loss: 0.6167319076401847   837  0.5059755146503448\n",
      "Training loss: 0.6185136905738285   838  0.4831158071756363\n",
      "Training loss: 0.616244946207319   839  0.4914914518594742\n",
      "Training loss: 0.6140526788575309   840  0.4936794936656952\n",
      "Training loss: 0.6169600657054356   841  0.5071889907121658\n",
      "Training loss: 0.6163196393421718   842  0.49223482608795166\n",
      "Training loss: 0.611504886831556   843  0.5035101771354675\n",
      "Training loss: 0.613898264510291   844  0.48880867660045624\n",
      "Training loss: 0.6116288900375366   845  0.49643801152706146\n",
      "Training loss: 0.6183728320258004   846  0.4836393743753433\n",
      "Training loss: 0.6159847165857043   847  0.49359363317489624\n",
      "Training loss: 0.6100438790661948   848  0.5016420036554337\n",
      "Training loss: 0.6124850000653949   849  0.49762314558029175\n",
      "Training loss: 0.615869973387037   850  0.49111291766166687\n",
      "Training loss: 0.6125590460641044   851  0.5025568902492523\n",
      "Training loss: 0.6093834894044059   852  0.4838571846485138\n",
      "Training loss: 0.6118019606385913   853  0.501644030213356\n",
      "Training loss: 0.6150942104203361   854  0.4981353282928467\n",
      "Training loss: 0.6154618263244629   855  0.4929579943418503\n",
      "Training loss: 0.616565214736121   856  0.5082037597894669\n",
      "Training loss: 0.6176247469016484   857  0.5045559257268906\n",
      "Training loss: 0.6149767850126538   858  0.4915097951889038\n",
      "Training loss: 0.6127855096544538   859  0.4948464334011078\n",
      "Training loss: 0.6090917757579258   860  0.4992281496524811\n",
      "Training loss: 0.6111426566328321   861  0.491416797041893\n",
      "Training loss: 0.6100091636180878   862  0.49601176381111145\n",
      "Training loss: 0.6134541034698486   863  0.48099522292613983\n",
      "Training loss: 0.6095391639641353   864  0.509946420788765\n",
      "Training loss: 0.6126385586602348   865  0.4993886351585388\n",
      "Training loss: 0.6084223283188683   866  0.49834710359573364\n",
      "Training loss: 0.6178690109934125   867  0.49418099224567413\n",
      "Training loss: 0.6086953069482531   868  0.4899948686361313\n",
      "Training loss: 0.6093437118189675   869  0.4905637949705124\n",
      "Training loss: 0.6113963169710976   870  0.48858268558979034\n",
      "Training loss: 0.6094740884644645   871  0.49279138445854187\n",
      "Training loss: 0.6134058279650552   872  0.4925593286752701\n",
      "Training loss: 0.6066919650350299   873  0.4869935065507889\n",
      "Training loss: 0.6075827309063503   874  0.48900215327739716\n",
      "Training loss: 0.6053404680320195   875  0.4816530793905258\n",
      "Training loss: 0.6104700693062374   876  0.4932951331138611\n",
      "Training loss: 0.6070790546280997   877  0.4804474413394928\n",
      "Training loss: 0.6102240724223   878  0.48462696373462677\n",
      "Training loss: 0.6083628620420184   879  0.495758518576622\n",
      "Training loss: 0.6108921595982143   880  0.49037787318229675\n",
      "Training loss: 0.6083859290395465   881  0.4973915219306946\n",
      "Training loss: 0.6066943790231433   882  0.4738215208053589\n",
      "Training loss: 0.6066649683884212   883  0.4972376227378845\n",
      "Training loss: 0.6112698827471051   884  0.49169033765792847\n",
      "Training loss: 0.6081874626023429   885  0.4829310029745102\n",
      "Training loss: 0.6073836130755288   886  0.49865953624248505\n",
      "Training loss: 0.6048792856080192   887  0.49092330038547516\n",
      "Training loss: 0.6064899946962085   888  0.4841904789209366\n",
      "Training loss: 0.6056350043841771   889  0.4785301238298416\n",
      "Training loss: 0.6033504136971065   890  0.4764973074197769\n",
      "Training loss: 0.6068259605339595   891  0.47778162360191345\n",
      "Training loss: 0.610917580979211   892  0.48379139602184296\n",
      "Training loss: 0.6104692987033299   893  0.5028692483901978\n",
      "Training loss: 0.617481951202665   894  0.5039067715406418\n",
      "Training loss: 0.6080177639211927   895  0.48209331929683685\n",
      "Training loss: 0.6099212637969426   896  0.49501416087150574\n",
      "Training loss: 0.6101763461317334   897  0.4887247830629349\n",
      "Training loss: 0.611289748123714   898  0.49364225566387177\n",
      "Training loss: 0.6092354101794106   899  0.4816069006919861\n",
      "Training loss: 0.6073507624013084   900  0.47994160652160645\n",
      "Training loss: 0.6088853393282209   901  0.4860555827617645\n",
      "Training loss: 0.6056121162005833   902  0.48718276619911194\n",
      "Training loss: 0.6072064467838832   903  0.49501171708106995\n",
      "Training loss: 0.6054815394537789   904  0.48269328474998474\n",
      "Training loss: 0.6051198669842311   905  0.4702720046043396\n",
      "Training loss: 0.6056674122810364   906  0.4921680688858032\n",
      "Training loss: 0.6051291099616459   907  0.4885891377925873\n",
      "Training loss: 0.6084202144827161   908  0.48191066086292267\n",
      "Training loss: 0.6037434722696032   909  0.48926740884780884\n",
      "Training loss: 0.6070025180067334   910  0.4794798493385315\n",
      "Training loss: 0.6016495823860168   911  0.5024596601724625\n",
      "Training loss: 0.6089329464094979   912  0.49461689591407776\n",
      "Training loss: 0.6084405566964831   913  0.48635338246822357\n",
      "Training loss: 0.6061124929359981   914  0.47987280786037445\n",
      "Training loss: 0.606946553502764   915  0.5020723640918732\n",
      "Training loss: 0.6160918559346881   916  0.5070942342281342\n",
      "Training loss: 0.6149140489952905   917  0.4873243421316147\n",
      "Training loss: 0.6115269788673946   918  0.4950625002384186\n",
      "Training loss: 0.6071498053414481   919  0.48075859248638153\n",
      "Training loss: 0.6081770658493042   920  0.4790593683719635\n",
      "Training loss: 0.6018314361572266   921  0.4921726584434509\n",
      "Training loss: 0.6062248732362475   922  0.48777294158935547\n",
      "Training loss: 0.6016534396580288   923  0.4941817671060562\n",
      "Training loss: 0.6195223586899894   924  0.4934120774269104\n",
      "Training loss: 0.6202748460429055   925  0.5020636469125748\n",
      "Training loss: 0.6130662943635669   926  0.5058373361825943\n",
      "Training loss: 0.6086250288145882   927  0.48958784341812134\n",
      "Training loss: 0.6071337844644275   928  0.48695218563079834\n",
      "Training loss: 0.6054353373391288   929  0.49445173144340515\n",
      "Training loss: 0.6048669559614999   930  0.47923794388771057\n",
      "Training loss: 0.6004424435751778   931  0.48595933616161346\n",
      "Training loss: 0.6044297090598515   932  0.4936036318540573\n",
      "Training loss: 0.6038228699139186   933  0.4897276908159256\n",
      "Training loss: 0.6022816981588092   934  0.49883028864860535\n",
      "Training loss: 0.6059837767056057   935  0.47593313455581665\n",
      "Training loss: 0.6034062121595655   936  0.4972054213285446\n",
      "Training loss: 0.6056007444858551   937  0.4881124645471573\n",
      "Training loss: 0.6053438910416195   938  0.4872915744781494\n",
      "Training loss: 0.6016946179526192   939  0.48835289478302\n",
      "Training loss: 0.6052642209189278   940  0.47695593535900116\n",
      "Training loss: 0.6026951798370906   941  0.48485995829105377\n",
      "Training loss: 0.6024296155997685   942  0.5026094019412994\n",
      "Training loss: 0.6006521114281246   943  0.4981023520231247\n",
      "Training loss: 0.5983273131506783   944  0.4856730103492737\n",
      "Training loss: 0.5983551400048392   945  0.4724379926919937\n",
      "Training loss: 0.6027783794062478   946  0.4812093526124954\n",
      "Training loss: 0.6032094699995858   947  0.47472529113292694\n",
      "Training loss: 0.5998044439724514   948  0.4829694926738739\n",
      "Training loss: 0.6027639550822121   949  0.48109231889247894\n",
      "Training loss: 0.6013955303600856   950  0.49311496317386627\n",
      "Training loss: 0.5996899689946856   951  0.487532302737236\n",
      "Training loss: 0.6018121455396924   952  0.47812099754810333\n",
      "Training loss: 0.6035982923848289   953  0.4720914512872696\n",
      "Training loss: 0.6002025561673301   954  0.48327840864658356\n",
      "Training loss: 0.5990799239703587   955  0.4981229305267334\n",
      "Training loss: 0.5989788472652435   956  0.4753766357898712\n",
      "Training loss: 0.6049002664429801   957  0.475276917219162\n",
      "Training loss: 0.6101556207452502   958  0.48019787669181824\n",
      "Training loss: 0.6009485082966941   959  0.4733176678419113\n",
      "Training loss: 0.6077228954860142   960  0.48369793593883514\n",
      "Training loss: 0.6020031188215528   961  0.4791542589664459\n",
      "Training loss: 0.6012035991464343   962  0.4825001209974289\n",
      "Training loss: 0.6063437930175236   963  0.48730315268039703\n",
      "Training loss: 0.6056097234998431   964  0.4849245548248291\n",
      "Training loss: 0.6011256064687457   965  0.49089184403419495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.6002419378076281   966  0.48662659525871277\n",
      "Training loss: 0.6017595657280513   967  0.48257263004779816\n",
      "Training loss: 0.6045685708522797   968  0.4830608516931534\n",
      "Training loss: 0.6021341596330915   969  0.4741179347038269\n",
      "Training loss: 0.6020148949963706   970  0.4897394925355911\n",
      "Training loss: 0.6031214424542019   971  0.4908096343278885\n",
      "Training loss: 0.6037228405475616   972  0.48600248992443085\n",
      "Training loss: 0.6003539902823312   973  0.4632849544286728\n",
      "Training loss: 0.5998284476143974   974  0.4752204567193985\n",
      "Training loss: 0.5958881718771798   975  0.4764844924211502\n",
      "Training loss: 0.6004704875605447   976  0.47711534798145294\n",
      "Training loss: 0.5989083349704742   977  0.4975952059030533\n",
      "Training loss: 0.6005068421363831   978  0.4811215102672577\n",
      "Training loss: 0.597920651946749   979  0.4861353039741516\n",
      "Training loss: 0.5977974236011505   980  0.4714478552341461\n",
      "Training loss: 0.5997378953865596   981  0.4929652214050293\n",
      "Training loss: 0.6000975114958627   982  0.47538693249225616\n",
      "Training loss: 0.5941313420023236   983  0.4847654700279236\n",
      "Training loss: 0.5988867112568447   984  0.4713522344827652\n",
      "Training loss: 0.5964570300919669   985  0.48131412267684937\n",
      "Training loss: 0.5978798355375018   986  0.4761013835668564\n",
      "Training loss: 0.5975228122302464   987  0.4885875880718231\n",
      "Training loss: 0.5959748455456325   988  0.48059114813804626\n",
      "Training loss: 0.5988588333129883   989  0.4826328158378601\n",
      "Training loss: 0.5972154268196651   990  0.48542359471321106\n",
      "Training loss: 0.5976015542234693   991  0.4742944836616516\n",
      "Training loss: 0.5939746924809047   992  0.4797614961862564\n",
      "Training loss: 0.5967744844300407   993  0.5024478286504745\n",
      "Training loss: 0.5960165347371783   994  0.48517923057079315\n",
      "Training loss: 0.5980005306856973   995  0.49410247802734375\n",
      "Training loss: 0.5996118911675045   996  0.4867866188287735\n",
      "Training loss: 0.5957417913845607   997  0.4689116030931473\n",
      "Training loss: 0.5996736628668649   998  0.4815707951784134\n",
      "Training loss: 0.597061778817858   999  0.4838043600320816\n",
      "Training loss: 0.591502423797335   1000  0.4826943725347519\n",
      "Training loss: 0.5944835756506238   1001  0.47668348252773285\n",
      "Training loss: 0.5942618037973132   1002  0.4892807900905609\n",
      "Training loss: 0.5987754208700997   1003  0.4899383783340454\n",
      "Training loss: 0.600902225290026   1004  0.48342491686344147\n",
      "Training loss: 0.5965817868709564   1005  0.48798517882823944\n",
      "Training loss: 0.5960998662880489   1006  0.4865712672472\n",
      "Training loss: 0.5996187371867043   1007  0.48461076617240906\n",
      "Training loss: 0.5968396067619324   1008  0.4852650612592697\n",
      "Training loss: 0.6016931916986193   1009  0.48890507221221924\n",
      "Training loss: 0.5948566028050014   1010  0.48785868287086487\n",
      "Training loss: 0.5952889323234558   1011  0.48340222239494324\n",
      "Training loss: 0.5940450089318412   1012  0.4721077233552933\n",
      "Training loss: 0.5999390482902527   1013  0.4805683344602585\n",
      "Training loss: 0.5965223269803184   1014  0.4770003855228424\n",
      "Training loss: 0.59249894959586   1015  0.46404580771923065\n",
      "Training loss: 0.5948515108653477   1016  0.49652788043022156\n",
      "Training loss: 0.5947732073920113   1017  0.4665271043777466\n",
      "Training loss: 0.5931122260434287   1018  0.48237884044647217\n",
      "Training loss: 0.5930759906768799   1019  0.4951726496219635\n",
      "Training loss: 0.5916027469294411   1020  0.49281975626945496\n",
      "Training loss: 0.5938607752323151   1021  0.4582633972167969\n",
      "Training loss: 0.594458418233054   1022  0.4750407338142395\n",
      "Training loss: 0.5954776661736625   1023  0.48917432129383087\n",
      "Training loss: 0.5947647179876056   1024  0.4982333779335022\n",
      "Training loss: 0.5981394563402448   1025  0.4915136396884918\n",
      "Training loss: 0.6025848346097129   1026  0.4848098158836365\n",
      "Training loss: 0.5981604967798505   1027  0.4906568229198456\n",
      "Training loss: 0.59730207494327   1028  0.4796828627586365\n",
      "Training loss: 0.6010103012834277   1029  0.49122314155101776\n",
      "Training loss: 0.5976732245513371   1030  0.4719729423522949\n",
      "Training loss: 0.5994016996451786   1031  0.47670693695545197\n",
      "Training loss: 0.5925192492348808   1032  0.46140603721141815\n",
      "Training loss: 0.5929195668016162   1033  0.47846174240112305\n",
      "Training loss: 0.5911552224840436   1034  0.4847264885902405\n",
      "Training loss: 0.5940444086279187   1035  0.4794069826602936\n",
      "Training loss: 0.597724084343229   1036  0.46791917085647583\n",
      "Training loss: 0.5900822579860687   1037  0.478092759847641\n",
      "Training loss: 0.5941399591309684   1038  0.4770447462797165\n",
      "Training loss: 0.5920849229608264   1039  0.48782865703105927\n",
      "Training loss: 0.5906777722494942   1040  0.4737081676721573\n",
      "Training loss: 0.5951930156775883   1041  0.48604288697242737\n",
      "Training loss: 0.5960963240691594   1042  0.4751904308795929\n",
      "Training loss: 0.5928825438022614   1043  0.4907151162624359\n",
      "Training loss: 0.5898690266268594   1044  0.4708741158246994\n",
      "Training loss: 0.5916604953152793   1045  0.4790493845939636\n",
      "Training loss: 0.590033267225538   1046  0.47259415686130524\n",
      "Training loss: 0.590861724955695   1047  0.48018769919872284\n",
      "Training loss: 0.5978770852088928   1048  0.4765089750289917\n",
      "Training loss: 0.5921754794461387   1049  0.4782849848270416\n",
      "Training loss: 0.5895440024988992   1050  0.47391435503959656\n",
      "Training loss: 0.596850505896977   1051  0.48026441037654877\n",
      "Training loss: 0.5981299792017255   1052  0.48666583001613617\n",
      "Training loss: 0.5990549368517739   1053  0.48066848516464233\n",
      "Training loss: 0.5936219905103955   1054  0.5004604607820511\n",
      "Training loss: 0.5886758395603725   1055  0.48997823894023895\n",
      "Training loss: 0.5922744785036359   1056  0.48087988793849945\n",
      "Training loss: 0.591065696307591   1057  0.47325220704078674\n",
      "Training loss: 0.5976128237588065   1058  0.46678462624549866\n",
      "Training loss: 0.5921447191919599   1059  0.46996070444583893\n",
      "Training loss: 0.59128708924566   1060  0.4897029995918274\n",
      "Training loss: 0.5916622536523002   1061  0.47520147264003754\n",
      "Training loss: 0.591568125145776   1062  0.46184056997299194\n",
      "Training loss: 0.5940686890057155   1063  0.48406560719013214\n",
      "Training loss: 0.5897419026919773   1064  0.47645387053489685\n",
      "Training loss: 0.5944524492536273   1065  0.47773388028144836\n",
      "Training loss: 0.5879512258938381   1066  0.4817298799753189\n",
      "Training loss: 0.590244995696204   1067  0.47932611405849457\n",
      "Training loss: 0.5905034073761531   1068  0.4700082689523697\n",
      "Training loss: 0.5856907154832568   1069  0.47981736063957214\n",
      "Training loss: 0.5898212449891227   1070  0.4848133474588394\n",
      "Training loss: 0.5917794363839286   1071  0.46493691205978394\n",
      "Training loss: 0.5914281819547925   1072  0.4677117317914963\n",
      "Training loss: 0.5859746890408652   1073  0.4783027321100235\n",
      "Training loss: 0.587214891399656   1074  0.4827774465084076\n",
      "Training loss: 0.5846160267080579   1075  0.47105278074741364\n",
      "Training loss: 0.588028392621449   1076  0.478343665599823\n",
      "Training loss: 0.5885730130331857   1077  0.48457661271095276\n",
      "Training loss: 0.590909114905766   1078  0.47866682708263397\n",
      "Training loss: 0.5884255724293845   1079  0.47665737569332123\n",
      "Training loss: 0.5881085182939257   1080  0.477340891957283\n",
      "Training loss: 0.5902141886098045   1081  0.4664699584245682\n",
      "Training loss: 0.5843197745936257   1082  0.4784930795431137\n",
      "Training loss: 0.58991767678942   1083  0.46333809196949005\n",
      "Training loss: 0.5865891405514309   1084  0.4633265435695648\n",
      "Training loss: 0.5876657962799072   1085  0.4678148478269577\n",
      "Training loss: 0.5893411934375763   1086  0.4823373258113861\n",
      "Training loss: 0.5881334543228149   1087  0.4739232659339905\n",
      "Training loss: 0.5880891297544751   1088  0.47027431428432465\n",
      "Training loss: 0.5891727719988141   1089  0.47489558160305023\n",
      "Training loss: 0.5897996042455945   1090  0.4838841110467911\n",
      "Training loss: 0.5865240352494376   1091  0.476114884018898\n",
      "Training loss: 0.5848205643040794   1092  0.47618748247623444\n",
      "Training loss: 0.5854818395205906   1093  0.4794060289859772\n",
      "Training loss: 0.5856023728847504   1094  0.46952395141124725\n",
      "Training loss: 0.5887612189565387   1095  0.45497721433639526\n",
      "Training loss: 0.5860516471522195   1096  0.46010592579841614\n",
      "Training loss: 0.5882137417793274   1097  0.47187764942646027\n",
      "Training loss: 0.5813946723937988   1098  0.47051049768924713\n",
      "Training loss: 0.5890701796327319   1099  0.4622291922569275\n",
      "Training loss: 0.5862702897616795   1100  0.47028258442878723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.5910872859614236   1101  0.45568811893463135\n",
      "Training loss: 0.588372256074633   1102  0.4712979942560196\n",
      "Training loss: 0.5844032466411591   1103  0.47956767678260803\n",
      "Training loss: 0.5865390343325478   1104  0.4697035551071167\n",
      "Training loss: 0.5856971527848925   1105  0.4732683449983597\n",
      "Training loss: 0.5882338796343122   1106  0.4745517522096634\n",
      "Training loss: 0.5776189565658569   1107  0.4706420302391052\n",
      "Training loss: 0.5845387620585305   1108  0.469683438539505\n",
      "Training loss: 0.5822222360542842   1109  0.46291889250278473\n",
      "Training loss: 0.584963892187391   1110  0.48207075893878937\n",
      "Training loss: 0.5883955402033669   1111  0.4689003527164459\n",
      "Training loss: 0.5808417201042175   1112  0.47499875724315643\n",
      "Training loss: 0.5879019456250327   1113  0.4703832119703293\n",
      "Training loss: 0.5870437707219806   1114  0.46797388792037964\n",
      "Training loss: 0.5843592882156372   1115  0.4701295346021652\n",
      "Training loss: 0.5856105174337115   1116  0.46682108938694\n",
      "Training loss: 0.5851393810340336   1117  0.48406124114990234\n",
      "Training loss: 0.588370510510036   1118  0.46875207126140594\n",
      "Training loss: 0.5889903647559029   1119  0.4741651564836502\n",
      "Training loss: 0.5858493362154279   1120  0.4843780994415283\n",
      "Training loss: 0.5848114660808018   1121  0.4588886797428131\n",
      "Training loss: 0.5796934919697898   1122  0.46302148699760437\n",
      "Training loss: 0.5863448807171413   1123  0.4686707854270935\n",
      "Training loss: 0.5858082728726524   1124  0.4770989418029785\n",
      "Training loss: 0.5839770010539463   1125  0.4638202339410782\n",
      "Training loss: 0.5855514662606376   1126  0.4724368453025818\n",
      "Training loss: 0.5878948398998806   1127  0.47698885202407837\n",
      "Training loss: 0.5864256705556598   1128  0.4682529419660568\n",
      "Training loss: 0.5852915644645691   1129  0.46619659662246704\n",
      "Training loss: 0.5856099128723145   1130  0.47311611473560333\n",
      "Training loss: 0.5861027921949115   1131  0.46458305418491364\n",
      "Training loss: 0.5837191726480212   1132  0.4703207463026047\n",
      "Training loss: 0.579804003238678   1133  0.4735305607318878\n",
      "Training loss: 0.5879745440823692   1134  0.4761675149202347\n",
      "Training loss: 0.5869036657469613   1135  0.46827226877212524\n",
      "Training loss: 0.5875535309314728   1136  0.47932611405849457\n",
      "Training loss: 0.5810807262148175   1137  0.4734652042388916\n",
      "Training loss: 0.5867745876312256   1138  0.4703136831521988\n",
      "Training loss: 0.5838699553694043   1139  0.45127004384994507\n",
      "Training loss: 0.5844751809324537   1140  0.47751253843307495\n",
      "Training loss: 0.5872677905218942   1141  0.4645678251981735\n",
      "Training loss: 0.5802739347730365   1142  0.48215673863887787\n",
      "Training loss: 0.5832547673157283   1143  0.4638037383556366\n",
      "Training loss: 0.5861181191035679   1144  0.47399841248989105\n",
      "Training loss: 0.5841219254902431   1145  0.4616033136844635\n",
      "Training loss: 0.5813610809189933   1146  0.47999297082424164\n",
      "Training loss: 0.5838506051472255   1147  0.47981469333171844\n",
      "Training loss: 0.5830762599195752   1148  0.4732533246278763\n",
      "Training loss: 0.5788314768246242   1149  0.4623657166957855\n",
      "Training loss: 0.5855318137577602   1150  0.46495355665683746\n",
      "Training loss: 0.5819838004452842   1151  0.47063612937927246\n",
      "Training loss: 0.581375173160008   1152  0.46889930963516235\n",
      "Training loss: 0.5815103777817318   1153  0.47828851640224457\n",
      "Training loss: 0.5873283020087651   1154  0.46864694356918335\n",
      "Training loss: 0.5824341092790876   1155  0.4620710015296936\n",
      "Training loss: 0.5864355478967939   1156  0.47602300345897675\n",
      "Training loss: 0.5852999091148376   1157  0.46002548933029175\n",
      "Training loss: 0.5775550433567592   1158  0.4657025933265686\n",
      "Training loss: 0.5796118336064475   1159  0.46528251469135284\n",
      "Training loss: 0.5790763412203107   1160  0.47497160732746124\n",
      "Training loss: 0.5829572422163827   1161  0.4587719589471817\n",
      "Training loss: 0.5818563571998051   1162  0.46182243525981903\n",
      "Training loss: 0.5824826189449855   1163  0.46759264171123505\n",
      "Training loss: 0.5822253738130841   1164  0.4632151573896408\n",
      "Training loss: 0.5808758735656738   1165  0.4728628098964691\n",
      "Training loss: 0.5782291506017957   1166  0.46630120277404785\n",
      "Training loss: 0.5774913345064435   1167  0.4766210615634918\n",
      "Training loss: 0.581278247492654   1168  0.4558802992105484\n",
      "Training loss: 0.5803330625806536   1169  0.46182967722415924\n",
      "Training loss: 0.5806014239788055   1170  0.4698280543088913\n",
      "Training loss: 0.5789028065545219   1171  0.45830798149108887\n",
      "Training loss: 0.5810083959783826   1172  0.4685945510864258\n",
      "Training loss: 0.5816643876688821   1173  0.4679707884788513\n",
      "Training loss: 0.5824366211891174   1174  0.4639133810997009\n",
      "Training loss: 0.5821056663990021   1175  0.4695727527141571\n",
      "Training loss: 0.5822628779070718   1176  0.4695885479450226\n",
      "Training loss: 0.5779011504990714   1177  0.47315458953380585\n",
      "Training loss: 0.5783547290733883   1178  0.473313570022583\n",
      "Training loss: 0.579465925693512   1179  0.47280876338481903\n",
      "Training loss: 0.576918465750558   1180  0.46433626115322113\n",
      "Training loss: 0.5766998742307935   1181  0.470731645822525\n",
      "Training loss: 0.5789989616189685   1182  0.46624845266342163\n",
      "Training loss: 0.5822987641607013   1183  0.46643592417240143\n",
      "Training loss: 0.5807195092950549   1184  0.46160610020160675\n",
      "Training loss: 0.5770438781806401   1185  0.46541351079940796\n",
      "Training loss: 0.5795485717909676   1186  0.46331603825092316\n",
      "Training loss: 0.5809390544891357   1187  0.46106621623039246\n",
      "Training loss: 0.5795635623591286   1188  0.46483223140239716\n",
      "Training loss: 0.5814617531640189   1189  0.47758153080940247\n",
      "Training loss: 0.5826021901198796   1190  0.46351541578769684\n",
      "Training loss: 0.5802452691963741   1191  0.460139736533165\n",
      "Training loss: 0.5798700749874115   1192  0.4771376997232437\n",
      "Training loss: 0.58548546901771   1193  0.4730300307273865\n",
      "Training loss: 0.5851932849202838   1194  0.4757618010044098\n",
      "Training loss: 0.5831031714166913   1195  0.46485409140586853\n",
      "Training loss: 0.5847654129777636   1196  0.4712454080581665\n",
      "Training loss: 0.5832636739526477   1197  0.4705325961112976\n",
      "Training loss: 0.580892984356199   1198  0.4662584513425827\n",
      "Training loss: 0.5804684204714639   1199  0.4846450835466385\n",
      "Training loss: 0.5763400452477592   1200  0.4717039316892624\n",
      "Training loss: 0.581031505550657   1201  0.45582935214042664\n",
      "Training loss: 0.5747378723961967   1202  0.46694284677505493\n",
      "Training loss: 0.5791888407298497   1203  0.46650266647338867\n",
      "Training loss: 0.5799627431801387   1204  0.45464253425598145\n",
      "Training loss: 0.5797336484704699   1205  0.4662986397743225\n",
      "Training loss: 0.5786616376468113   1206  0.468218594789505\n",
      "Training loss: 0.5818304462092263   1207  0.4691631644964218\n",
      "Training loss: 0.5800538041761943   1208  0.46926113963127136\n",
      "Training loss: 0.5785617360046932   1209  0.4642743766307831\n",
      "Training loss: 0.5763155945709774   1210  0.4591722637414932\n",
      "Training loss: 0.5820219005857196   1211  0.4624790549278259\n",
      "Training loss: 0.5784424202782767   1212  0.4648018032312393\n",
      "Training loss: 0.5765995596136365   1213  0.47293759882450104\n",
      "Training loss: 0.5777731793267387   1214  0.460349440574646\n",
      "Training loss: 0.5790677070617676   1215  0.4664025604724884\n",
      "Training loss: 0.5749702113015311   1216  0.45297984778881073\n",
      "Training loss: 0.5764160837445941   1217  0.46304982900619507\n",
      "Training loss: 0.5766130260058812   1218  0.46433448791503906\n",
      "Training loss: 0.5812235815184457   1219  0.4635056406259537\n",
      "Training loss: 0.5782102814742497   1220  0.46502088010311127\n",
      "Training loss: 0.577063283749989   1221  0.4686714708805084\n",
      "Training loss: 0.577572728906359   1222  0.4677189737558365\n",
      "Training loss: 0.5795216986111232   1223  0.46950629353523254\n",
      "Training loss: 0.5808105553899493   1224  0.4696618765592575\n",
      "Training loss: 0.5812790500266212   1225  0.4740453362464905\n",
      "Training loss: 0.578479813677924   1226  0.45506082475185394\n",
      "Training loss: 0.5807564514023917   1227  0.4607905149459839\n",
      "Training loss: 0.5788671331746238   1228  0.45966869592666626\n",
      "Training loss: 0.5740350101675306   1229  0.45913806557655334\n",
      "Training loss: 0.577392156635012   1230  0.451388955116272\n",
      "Training loss: 0.5793471762112209   1231  0.45976918935775757\n",
      "Training loss: 0.5812776684761047   1232  0.4744139164686203\n",
      "Training loss: 0.5811471045017242   1233  0.4489889293909073\n",
      "Training loss: 0.576900737626212   1234  0.457337886095047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.5776088791234153   1235  0.4790494441986084\n",
      "Training loss: 0.5786903159958976   1236  0.46058332920074463\n",
      "Training loss: 0.5818119943141937   1237  0.4731191396713257\n",
      "Training loss: 0.5792603535311562   1238  0.4578884541988373\n",
      "Training loss: 0.575497784784862   1239  0.4700542241334915\n",
      "Training loss: 0.5736134818622044   1240  0.4741811603307724\n",
      "Training loss: 0.5735868343285152   1241  0.4702860116958618\n",
      "Training loss: 0.5770561503512519   1242  0.47801701724529266\n",
      "Training loss: 0.5802845273699079   1243  0.4718027859926224\n",
      "Training loss: 0.5811254296983991   1244  0.4612143635749817\n",
      "Training loss: 0.5784244452204023   1245  0.478737011551857\n",
      "Training loss: 0.5792040313993182   1246  0.4663432687520981\n",
      "Training loss: 0.5773881503513881   1247  0.4621778577566147\n",
      "Training loss: 0.5777587252003806   1248  0.46408241987228394\n",
      "Training loss: 0.5771292490618569   1249  0.4778168350458145\n",
      "Training loss: 0.5745001264980861   1250  0.47272542119026184\n",
      "Training loss: 0.5813624560832977   1251  0.4514317065477371\n",
      "Training loss: 0.5785919087273734   1252  0.46787241101264954\n",
      "Training loss: 0.5817774151052747   1253  0.4688723236322403\n",
      "Training loss: 0.5786539145878383   1254  0.46070559322834015\n",
      "Training loss: 0.5777969786099025   1255  0.45201385021209717\n",
      "Training loss: 0.5722892795290265   1256  0.4661732614040375\n",
      "Training loss: 0.5830539550100055   1257  0.47683802247047424\n",
      "Training loss: 0.5763887975897107   1258  0.4613727480173111\n",
      "Training loss: 0.5746989590781075   1259  0.47407732903957367\n",
      "Training loss: 0.5780791171959468   1260  0.4613291472196579\n",
      "Training loss: 0.5750439081873212   1261  0.46168558299541473\n",
      "Training loss: 0.5765551413808551   1262  0.47303085029125214\n",
      "Training loss: 0.5840215470109668   1263  0.45952682197093964\n",
      "Training loss: 0.5820545724460057   1264  0.47528399527072906\n",
      "Training loss: 0.5739815405436924   1265  0.45014795660972595\n",
      "Training loss: 0.5757407162870679   1266  0.47125791013240814\n",
      "Training loss: 0.5796180622918266   1267  0.46329696476459503\n",
      "Training loss: 0.5750200705868858   1268  0.45740681886672974\n",
      "Training loss: 0.5757845086710793   1269  0.46607428789138794\n",
      "Training loss: 0.5722165661198753   1270  0.478262260556221\n",
      "Training loss: 0.5778168865612575   1271  0.4612620025873184\n",
      "Training loss: 0.5770130923816136   1272  0.45439770072698593\n",
      "Training loss: 0.5790581234863826   1273  0.47043150663375854\n",
      "Training loss: 0.5776608075414386   1274  0.4572727680206299\n",
      "Training loss: 0.5739683530160359   1275  0.4742106646299362\n",
      "Training loss: 0.5751124577862876   1276  0.4649456739425659\n",
      "Training loss: 0.5739088484219143   1277  0.45830728113651276\n",
      "Training loss: 0.5805437011378152   1278  0.46112021803855896\n",
      "Training loss: 0.5741159830774579   1279  0.4498351365327835\n",
      "Training loss: 0.572970164673669   1280  0.4774705618619919\n",
      "Training loss: 0.577180164200919   1281  0.4632290005683899\n",
      "Training loss: 0.5784886351653508   1282  0.45610345900058746\n",
      "Training loss: 0.5722540489264897   1283  0.46568553149700165\n",
      "Training loss: 0.5748601598399026   1284  0.48163902759552\n",
      "Training loss: 0.5759236173970359   1285  0.4676535278558731\n",
      "Training loss: 0.5744797204221997   1286  0.4697344899177551\n",
      "Training loss: 0.5797092488833836   1287  0.46561117470264435\n",
      "Training loss: 0.576957072530474   1288  0.46879592537879944\n",
      "Training loss: 0.5759749625410352   1289  0.4525236636400223\n",
      "Training loss: 0.5790785891669137   1290  0.4778885990381241\n",
      "Training loss: 0.5743699967861176   1291  0.45768046379089355\n",
      "Training loss: 0.5725939231259483   1292  0.4561471790075302\n",
      "Training loss: 0.5746484271117619   1293  0.46654391288757324\n",
      "Training loss: 0.5781643475805011   1294  0.46204499900341034\n",
      "Training loss: 0.5753800741263798   1295  0.47148793935775757\n",
      "Training loss: 0.571871497801372   1296  0.46720200777053833\n",
      "Training loss: 0.5776177389281136   1297  0.45926839113235474\n",
      "Training loss: 0.5756807923316956   1298  0.4612308740615845\n",
      "Training loss: 0.5757221494402204   1299  0.45951028168201447\n",
      "Training loss: 0.5772750335080283   1300  0.4573656916618347\n",
      "Training loss: 0.5733764043876103   1301  0.46577320992946625\n",
      "Training loss: 0.5724952093192509   1302  0.46949055790901184\n",
      "Training loss: 0.5745622026068824   1303  0.47265635430812836\n",
      "Training loss: 0.5747981752668109   1304  0.46649111807346344\n",
      "Training loss: 0.5725224230970655   1305  0.4524187743663788\n",
      "Training loss: 0.5741268949849265   1306  0.4635266363620758\n",
      "Training loss: 0.5765461623668671   1307  0.448199987411499\n",
      "Training loss: 0.5753626014505114   1308  0.4613067954778671\n",
      "Training loss: 0.5763297315154757   1309  0.46258991956710815\n",
      "Training loss: 0.5736683585814067   1310  0.4624888747930527\n",
      "Training loss: 0.5743319647652763   1311  0.4789748191833496\n",
      "Training loss: 0.5779506308691842   1312  0.44877491891384125\n",
      "Training loss: 0.5767231115273067   1313  0.45846448838710785\n",
      "Training loss: 0.5731690909181323   1314  0.4804824888706207\n",
      "Training loss: 0.5702715005193438   1315  0.47167885303497314\n",
      "Training loss: 0.5736092712197985   1316  0.4676553010940552\n",
      "Training loss: 0.5739361771515438   1317  0.472684770822525\n",
      "Training loss: 0.5776859607015338   1318  0.4564220607280731\n",
      "Training loss: 0.5775067125047956   1319  0.47090716660022736\n",
      "Training loss: 0.5718401074409485   1320  0.47143492102622986\n",
      "Training loss: 0.57984887276377   1321  0.4776352494955063\n",
      "Training loss: 0.5768155625888279   1322  0.46690623462200165\n",
      "Training loss: 0.5739632078579494   1323  0.4601987153291702\n",
      "Training loss: 0.5722595453262329   1324  0.4647410362958908\n",
      "Training loss: 0.5733941963740757   1325  0.46031512320041656\n",
      "Training loss: 0.5732078850269318   1326  0.45887310802936554\n",
      "Training loss: 0.5752016050474984   1327  0.45924602448940277\n",
      "Training loss: 0.5690816598279136   1328  0.4690849483013153\n",
      "Training loss: 0.572626667363303   1329  0.4580114334821701\n",
      "Training loss: 0.5741191123213086   1330  0.45656949281692505\n",
      "Training loss: 0.572941426719938   1331  0.4588629901409149\n",
      "Training loss: 0.5729181340762547   1332  0.4357721656560898\n",
      "Training loss: 0.5740567147731781   1333  0.478312149643898\n",
      "Training loss: 0.5709322605814252   1334  0.45154160261154175\n",
      "Training loss: 0.5759614386728832   1335  0.46141572296619415\n",
      "Training loss: 0.577317333647183   1336  0.45406876504421234\n",
      "Training loss: 0.5717019651617322   1337  0.46562954783439636\n",
      "Training loss: 0.5702286490372249   1338  0.4539964497089386\n",
      "Training loss: 0.5699580439499446   1339  0.46105003356933594\n",
      "Training loss: 0.573292442730495   1340  0.45168352127075195\n",
      "Training loss: 0.5753058450562614   1341  0.4785993695259094\n",
      "Training loss: 0.5707169898918697   1342  0.46138787269592285\n",
      "Training loss: 0.5740576939923423   1343  0.4603009670972824\n",
      "Training loss: 0.5719937980175018   1344  0.45664966106414795\n",
      "Training loss: 0.5764403215476445   1345  0.45394107699394226\n",
      "Training loss: 0.5785617360046932   1346  0.46616029739379883\n",
      "Training loss: 0.5742251915591103   1347  0.46451330184936523\n",
      "Training loss: 0.5725930077689034   1348  0.4703586846590042\n",
      "Training loss: 0.5719979192529406   1349  0.4719870984554291\n",
      "Training loss: 0.5756534295422691   1350  0.4768660217523575\n",
      "Training loss: 0.572074157851083   1351  0.4692416936159134\n",
      "Training loss: 0.57065178666796   1352  0.46597158908843994\n",
      "Training loss: 0.568809517792293   1353  0.45984090864658356\n",
      "Training loss: 0.570480295589992   1354  0.46800869703292847\n",
      "Training loss: 0.5748448584760938   1355  0.4627162665128708\n",
      "Training loss: 0.5702211516244071   1356  0.471170112490654\n",
      "Training loss: 0.573214420250484   1357  0.4745636582374573\n",
      "Training loss: 0.5722984373569489   1358  0.4631379395723343\n",
      "Training loss: 0.5757464596203395   1359  0.45493707060813904\n",
      "Training loss: 0.5708551066262382   1360  0.4565209597349167\n",
      "Training loss: 0.5734689363411495   1361  0.45569224655628204\n",
      "Training loss: 0.571548730134964   1362  0.4644710570573807\n",
      "Training loss: 0.5773736877100808   1363  0.46015919744968414\n",
      "Training loss: 0.573482734816415   1364  0.45337747037410736\n",
      "Training loss: 0.5748488988195147   1365  0.46466927230358124\n",
      "Training loss: 0.571876951626369   1366  0.47767767310142517\n",
      "Training loss: 0.5739188407148633   1367  0.4585098773241043\n",
      "Training loss: 0.5698995675359454   1368  0.4746311157941818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.5724784050668988   1369  0.45858004689216614\n",
      "Training loss: 0.5721273592540196   1370  0.45731478929519653\n",
      "Training loss: 0.5704870522022247   1371  0.4527444541454315\n",
      "Training loss: 0.574910146849496   1372  0.4551493972539902\n",
      "Training loss: 0.5728049618857247   1373  0.45870548486709595\n",
      "Training loss: 0.5770283937454224   1374  0.4499485343694687\n",
      "Training loss: 0.571453720331192   1375  0.4550154358148575\n",
      "Training loss: 0.5731653784002576   1376  0.4717656821012497\n",
      "Training loss: 0.5726062740598407   1377  0.47205862402915955\n",
      "Training loss: 0.5696632542780468   1378  0.455332487821579\n",
      "Training loss: 0.5685494669846126   1379  0.46363188326358795\n",
      "Training loss: 0.5667140441281455   1380  0.4598226100206375\n",
      "Training loss: 0.5760426095553807   1381  0.4573661684989929\n",
      "Training loss: 0.5723298873220172   1382  0.4666493237018585\n",
      "Training loss: 0.5692023166588375   1383  0.46205295622348785\n",
      "Training loss: 0.5750701725482941   1384  0.4611331671476364\n",
      "Training loss: 0.5716656574181148   1385  0.4595401883125305\n",
      "Training loss: 0.5710970716817039   1386  0.4731062948703766\n",
      "Training loss: 0.5745173224381038   1387  0.4714638888835907\n",
      "Training loss: 0.5710596527372088   1388  0.45694175362586975\n",
      "Training loss: 0.5688291319778987   1389  0.47354811429977417\n",
      "Training loss: 0.5720226849828448   1390  0.4494287818670273\n",
      "Training loss: 0.5667214521339962   1391  0.4562319666147232\n",
      "Training loss: 0.5749661752155849   1392  0.46268266439437866\n",
      "Training loss: 0.5743327268532344   1393  0.45437267422676086\n",
      "Training loss: 0.572888263634273   1394  0.45109739899635315\n",
      "Training loss: 0.5670507763113294   1395  0.4701821357011795\n",
      "Training loss: 0.5718007172857013   1396  0.45566026866436005\n",
      "Training loss: 0.5687758198806218   1397  0.4606392830610275\n",
      "Training loss: 0.5660024157592228   1398  0.46981772780418396\n",
      "Training loss: 0.5715419777802059   1399  0.45134297013282776\n",
      "Training loss: 0.5731751961367471   1400  0.467043399810791\n",
      "Training loss: 0.5723400222403663   1401  0.46465200185775757\n",
      "Training loss: 0.5709338358470372   1402  0.45230239629745483\n",
      "Training loss: 0.5705679910523551   1403  0.4586963951587677\n",
      "Training loss: 0.5706607912267957   1404  0.4558086395263672\n",
      "Training loss: 0.5745616214615958   1405  0.4600960612297058\n",
      "Training loss: 0.5748367096696582   1406  0.46431803703308105\n",
      "Training loss: 0.5742500296660832   1407  0.4495129734277725\n",
      "Training loss: 0.5725031495094299   1408  0.46264779567718506\n",
      "Training loss: 0.5700309297868184   1409  0.4531848877668381\n",
      "Training loss: 0.5709701904228756   1410  0.46105608344078064\n",
      "Training loss: 0.5686650914805276   1411  0.46731871366500854\n",
      "Training loss: 0.5681773381573814   1412  0.45485325157642365\n",
      "Training loss: 0.5706157173429217   1413  0.47261781990528107\n",
      "Training loss: 0.5691005140542984   1414  0.4580160677433014\n",
      "Training loss: 0.5665787415845054   1415  0.46524950861930847\n",
      "Training loss: 0.5712920555046627   1416  0.47929850220680237\n",
      "Training loss: 0.5698466045515878   1417  0.4629032015800476\n",
      "Training loss: 0.5672002221856799   1418  0.4582517296075821\n",
      "Training loss: 0.5685012766293117   1419  0.4461868852376938\n",
      "Training loss: 0.5688450485467911   1420  0.4629402607679367\n",
      "Training loss: 0.5649175856794629   1421  0.4619026482105255\n",
      "Training loss: 0.5723899517740522   1422  0.4736293852329254\n",
      "Training loss: 0.5725766399077007   1423  0.4536173790693283\n",
      "Training loss: 0.5695997561727252   1424  0.4432835727930069\n",
      "Training loss: 0.5654315437589373   1425  0.4485085606575012\n",
      "Training loss: 0.5721192785671779   1426  0.4633430987596512\n",
      "Training loss: 0.5741972029209137   1427  0.46519581973552704\n",
      "Training loss: 0.5738434663840702   1428  0.4604306071996689\n",
      "Training loss: 0.5713314712047577   1429  0.4679708629846573\n",
      "Training loss: 0.5710152472768512   1430  0.4434720128774643\n",
      "Training loss: 0.5669546723365784   1431  0.45900948345661163\n",
      "Training loss: 0.5752260301794324   1432  0.4603162258863449\n",
      "Training loss: 0.5679267261709485   1433  0.4544142037630081\n",
      "Training loss: 0.5712742762906211   1434  0.4617360085248947\n",
      "Training loss: 0.5693174643175942   1435  0.47054725885391235\n",
      "Training loss: 0.5665195499147687   1436  0.4674680531024933\n",
      "Training loss: 0.5751104546444756   1437  0.45356127619743347\n",
      "Training loss: 0.5701413112027305   1438  0.4637821167707443\n",
      "Training loss: 0.5680520023618426   1439  0.45573389530181885\n",
      "Training loss: 0.5684374187673841   1440  0.46408407390117645\n",
      "Training loss: 0.5659276672771999   1441  0.4638424962759018\n",
      "Training loss: 0.5655136023248944   1442  0.4818868488073349\n",
      "Training loss: 0.5677845009735653   1443  0.46684877574443817\n",
      "Training loss: 0.5654312031609672   1444  0.4545685350894928\n",
      "Training loss: 0.5678626469203404   1445  0.4529656618833542\n",
      "Training loss: 0.568526668207986   1446  0.4530304819345474\n",
      "Training loss: 0.5684478453227452   1447  0.4578787088394165\n",
      "Training loss: 0.5700768062046596   1448  0.4700087308883667\n",
      "Training loss: 0.5681168692452567   1449  0.466953307390213\n",
      "Training loss: 0.5648834024156842   1450  0.4666907787322998\n",
      "Training loss: 0.5690051700387683   1451  0.4638105481863022\n",
      "Training loss: 0.5668071465832847   1452  0.4439476430416107\n",
      "Training loss: 0.5687801923070636   1453  0.4655924588441849\n",
      "Training loss: 0.5696816231523242   1454  0.45745350420475006\n",
      "Training loss: 0.5704512468406132   1455  0.45707616209983826\n",
      "Training loss: 0.5646540480000632   1456  0.4648524969816208\n",
      "Training loss: 0.5660047658852169   1457  0.4507025480270386\n",
      "Training loss: 0.5664947926998138   1458  0.45940980315208435\n",
      "Training loss: 0.5675032266548702   1459  0.4483148530125618\n",
      "Training loss: 0.5665175446442196   1460  0.4559343606233597\n",
      "Training loss: 0.5689679426806313   1461  0.4509163647890091\n",
      "Training loss: 0.5660559066704342   1462  0.4625833183526993\n",
      "Training loss: 0.5675718741757529   1463  0.46287328004837036\n",
      "Training loss: 0.567715082849775   1464  0.4559671878814697\n",
      "Training loss: 0.5717835426330566   1465  0.45875246822834015\n",
      "Training loss: 0.5707812820162091   1466  0.45041118562221527\n",
      "Training loss: 0.5639390647411346   1467  0.4592754989862442\n",
      "Training loss: 0.5656319175447736   1468  0.45068205893039703\n",
      "Training loss: 0.569704566683088   1469  0.469482958316803\n",
      "Training loss: 0.5732282485280719   1470  0.45188379287719727\n",
      "Training loss: 0.5696719586849213   1471  0.46176597476005554\n",
      "Training loss: 0.5696542177881513   1472  0.4535202160477638\n",
      "Training loss: 0.5679360032081604   1473  0.46118366718292236\n",
      "Training loss: 0.5708196716649192   1474  0.45799821615219116\n",
      "Training loss: 0.5697244363171714   1475  0.45895034074783325\n",
      "Training loss: 0.5709148815699986   1476  0.4491151124238968\n",
      "Training loss: 0.5651734258447375   1477  0.4621944725513458\n",
      "Training loss: 0.56752781357084   1478  0.45598427951335907\n",
      "Training loss: 0.5695297207151141   1479  0.45228222012519836\n",
      "Training loss: 0.5683014733450753   1480  0.45047515630722046\n",
      "Training loss: 0.5672980759825025   1481  0.4559059143066406\n",
      "Training loss: 0.5661395405020032   1482  0.468481108546257\n",
      "Training loss: 0.5642361555780683   1483  0.4457910358905792\n",
      "Training loss: 0.5652389058044979   1484  0.4624648541212082\n",
      "Training loss: 0.5646429402487618   1485  0.4662470817565918\n",
      "Training loss: 0.5676819128649575   1486  0.4669639319181442\n",
      "Training loss: 0.5653895735740662   1487  0.46059535443782806\n",
      "Training loss: 0.5655826457909175   1488  0.4522610902786255\n",
      "Training loss: 0.5681061020919255   1489  0.4522572308778763\n",
      "Training loss: 0.5632239707878658   1490  0.46223606169223785\n",
      "Training loss: 0.5677525635276522   1491  0.46187901496887207\n",
      "Training loss: 0.5650018198149545   1492  0.4607936292886734\n",
      "Training loss: 0.5617577901908329   1493  0.46170173585414886\n",
      "Training loss: 0.5661394808973584   1494  0.45583029091358185\n",
      "Training loss: 0.5671605744532177   1495  0.46214281022548676\n",
      "Training loss: 0.5706622643130166   1496  0.4428415149450302\n",
      "Training loss: 0.5663293089185443   1497  0.4694755971431732\n",
      "Training loss: 0.5677003349576678   1498  0.46053898334503174\n",
      "Training loss: 0.5663380452564785   1499  0.449209526181221\n",
      "Training loss: 0.5644593834877014   1500  0.4509156197309494\n",
      "Training loss: 0.5703395051615578   1501  0.4575536996126175\n",
      "Training loss: 0.5642702622073037   1502  0.46209803223609924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.5679341086319515   1503  0.44674836099147797\n",
      "Training loss: 0.5665381678513118   1504  0.4599202573299408\n",
      "Training loss: 0.5679876761777061   1505  0.464203879237175\n",
      "Training loss: 0.5669963785580227   1506  0.4560896307229996\n",
      "Training loss: 0.5622967141015189   1507  0.455549031496048\n",
      "Training loss: 0.5676008675779615   1508  0.45632345974445343\n",
      "Training loss: 0.5637978826250348   1509  0.46251872181892395\n",
      "Training loss: 0.5683067270687648   1510  0.48047663271427155\n",
      "Training loss: 0.5687209580625806   1511  0.4577479660511017\n",
      "Training loss: 0.5664647945335933   1512  0.4567544162273407\n",
      "Training loss: 0.5655278435775212   1513  0.46738170087337494\n",
      "Training loss: 0.5720489961760384   1514  0.4592350125312805\n",
      "Training loss: 0.5734243903841291   1515  0.45426617562770844\n",
      "Training loss: 0.5658531061240605   1516  0.4617048054933548\n",
      "Training loss: 0.5643558331898281   1517  0.45430298149585724\n",
      "Training loss: 0.5647720439093453   1518  0.45077741146087646\n",
      "Training loss: 0.5673311310155051   1519  0.4552168548107147\n",
      "Training loss: 0.5703511663845607   1520  0.4561658501625061\n",
      "Training loss: 0.5722302581582751   1521  0.4570680856704712\n",
      "Training loss: 0.5661993622779846   1522  0.4673626273870468\n",
      "Training loss: 0.5677138439246586   1523  0.45133741199970245\n",
      "Training loss: 0.565700637442725   1524  0.4598543345928192\n",
      "Training loss: 0.5646037523235593   1525  0.4503619372844696\n",
      "Training loss: 0.5653318422181266   1526  0.455609530210495\n",
      "Training loss: 0.5626778389726367   1527  0.4638906419277191\n",
      "Training loss: 0.5646174337182727   1528  0.46414758265018463\n",
      "Training loss: 0.5652973822184971   1529  0.4557989686727524\n",
      "Training loss: 0.5657480529376439   1530  0.4653030335903168\n",
      "Training loss: 0.5675636380910873   1531  0.45566654205322266\n",
      "Training loss: 0.5672966114112309   1532  0.47255589067935944\n",
      "Training loss: 0.5684116014412471   1533  0.4577089548110962\n",
      "Training loss: 0.5663192570209503   1534  0.4527132660150528\n",
      "Training loss: 0.5651428018297467   1535  0.45600859820842743\n",
      "Training loss: 0.5650425255298615   1536  0.44712992012500763\n",
      "Training loss: 0.5653712621756962   1537  0.43953877687454224\n",
      "Training loss: 0.5620959060532706   1538  0.45922863483428955\n",
      "Training loss: 0.5659814349242619   1539  0.4605323076248169\n",
      "Training loss: 0.5675216657774789   1540  0.4619452804327011\n",
      "Training loss: 0.5658539916787829   1541  0.4701211601495743\n",
      "Training loss: 0.5627733043261937   1542  0.45999875664711\n",
      "Training loss: 0.5656611791678837   1543  0.4624333381652832\n",
      "Training loss: 0.5662696787289211   1544  0.4593774676322937\n",
      "Training loss: 0.5661969142300742   1545  0.4516688287258148\n",
      "Training loss: 0.5667830663067954   1546  0.454538032412529\n",
      "Training loss: 0.5660754357065473   1547  0.4560863524675369\n",
      "Training loss: 0.5623176991939545   1548  0.4563656896352768\n",
      "Training loss: 0.5635054154055459   1549  0.4488304406404495\n",
      "Training loss: 0.5677331600870404   1550  0.46157191693782806\n",
      "Training loss: 0.5631793098790305   1551  0.45773251354694366\n",
      "Training loss: 0.5605121638093676   1552  0.46235743165016174\n",
      "Training loss: 0.5627548226288387   1553  0.4570017606019974\n",
      "Training loss: 0.5645763618605477   1554  0.4568515568971634\n",
      "Training loss: 0.5681654214859009   1555  0.4554322212934494\n",
      "Training loss: 0.5670470893383026   1556  0.4495277553796768\n",
      "Training loss: 0.5692407297236579   1557  0.46608708798885345\n",
      "Training loss: 0.5629003388541085   1558  0.4538673385977745\n",
      "Training loss: 0.5690636719976153   1559  0.44600042700767517\n",
      "Training loss: 0.5665176851408822   1560  0.4557611644268036\n",
      "Training loss: 0.5633908425058637   1561  0.4522097557783127\n",
      "Training loss: 0.5632605850696564   1562  0.45215779542922974\n",
      "Training loss: 0.5692985483578273   1563  0.4555249512195587\n",
      "Training loss: 0.5671411114079612   1564  0.45914436876773834\n",
      "Training loss: 0.5663287426744189   1565  0.44899505376815796\n",
      "Training loss: 0.5618921369314194   1566  0.44913458824157715\n",
      "Training loss: 0.565765346799578   1567  0.4644244760274887\n",
      "Training loss: 0.565212858574731   1568  0.45953361690044403\n",
      "Training loss: 0.5598020723887852   1569  0.4504288211464882\n",
      "Training loss: 0.5628681012562343   1570  0.4605087786912918\n",
      "Training loss: 0.5606368396963392   1571  0.4635292887687683\n",
      "Training loss: 0.5647283749920982   1572  0.44375278055667877\n",
      "Training loss: 0.5670205397265298   1573  0.44457150995731354\n",
      "Training loss: 0.5691272275788444   1574  0.44658489525318146\n",
      "Training loss: 0.5655745778764997   1575  0.45247071981430054\n",
      "Training loss: 0.564647342477526   1576  0.4526032656431198\n",
      "Training loss: 0.5657405768121991   1577  0.455475315451622\n",
      "Training loss: 0.5625847109726497   1578  0.4594064950942993\n",
      "Training loss: 0.5636128485202789   1579  0.4549775719642639\n",
      "Training loss: 0.5657582793916974   1580  0.4592813700437546\n",
      "Training loss: 0.5636595828192574   1581  0.46164649724960327\n",
      "Training loss: 0.5647164476769311   1582  0.4678138792514801\n",
      "Training loss: 0.5651747754641941   1583  0.4529011398553848\n",
      "Training loss: 0.5578634228025164   1584  0.4622487872838974\n",
      "Training loss: 0.5579492918082646   1585  0.45104676485061646\n",
      "Training loss: 0.564556781734739   1586  0.46469756960868835\n",
      "Training loss: 0.5651538372039795   1587  0.4613439291715622\n",
      "Training loss: 0.5643958832536425   1588  0.45556096732616425\n",
      "Training loss: 0.5637556442192623   1589  0.4693988561630249\n",
      "Training loss: 0.5626023496900286   1590  0.46817751228809357\n",
      "Training loss: 0.5650573245116642   1591  0.45565029978752136\n",
      "Training loss: 0.5647939188139779   1592  0.470997616648674\n",
      "Training loss: 0.5662573661123004   1593  0.4506829082965851\n",
      "Training loss: 0.5720095080988747   1594  0.4531049281358719\n",
      "Training loss: 0.5686836072376796   1595  0.4511941969394684\n",
      "Training loss: 0.5645788929292134   1596  0.45212049782276154\n",
      "Training loss: 0.5637245859418597   1597  0.46255797147750854\n",
      "Training loss: 0.5654896071978978   1598  0.44607751071453094\n",
      "Training loss: 0.5666870219366891   1599  0.4483603537082672\n",
      "Training loss: 0.5643714325768607   1600  0.44561155140399933\n",
      "Training loss: 0.5643568422113147   1601  0.4414353370666504\n",
      "Training loss: 0.5629847858633313   1602  0.4496750235557556\n",
      "Training loss: 0.5643469989299774   1603  0.4505714327096939\n",
      "Training loss: 0.5614964195660183   1604  0.450139656662941\n",
      "Training loss: 0.5642716075692858   1605  0.4505559056997299\n",
      "Training loss: 0.562389429126467   1606  0.4519611895084381\n",
      "Training loss: 0.5625870483262199   1607  0.44639667868614197\n",
      "Training loss: 0.5595663573060717   1608  0.4592840000987053\n",
      "Training loss: 0.5630810814244407   1609  0.4546910673379898\n",
      "Training loss: 0.56464512859072   1610  0.4487949013710022\n",
      "Training loss: 0.5652569660118648   1611  0.4384630024433136\n",
      "Training loss: 0.5620838616575513   1612  0.44654107093811035\n",
      "Training loss: 0.5642842820712498   1613  0.46022820472717285\n",
      "Training loss: 0.5614402549607413   1614  0.45432335138320923\n",
      "Training loss: 0.5652362661702293   1615  0.45488105714321136\n",
      "Training loss: 0.5625977260725838   1616  0.4516178220510483\n",
      "Training loss: 0.5637656961168561   1617  0.44985267519950867\n",
      "Training loss: 0.5636094297681536   1618  0.45363475382328033\n",
      "Training loss: 0.5634598902293614   1619  0.45389382541179657\n",
      "Training loss: 0.5680513381958008   1620  0.4499069005250931\n",
      "Training loss: 0.5613315914358411   1621  0.4514707922935486\n",
      "Training loss: 0.5677232018538884   1622  0.4657003879547119\n",
      "Training loss: 0.5643514352185386   1623  0.4559967368841171\n",
      "Training loss: 0.5599542004721505   1624  0.4619985818862915\n",
      "Training loss: 0.565810352563858   1625  0.43832722306251526\n",
      "Training loss: 0.5598761694771903   1626  0.44669510424137115\n",
      "Training loss: 0.5628671858991895   1627  0.4554043561220169\n",
      "Training loss: 0.5650187177317483   1628  0.43140721321105957\n",
      "Training loss: 0.5637764100517545   1629  0.46908530592918396\n",
      "Training loss: 0.5633204281330109   1630  0.45639772713184357\n",
      "Training loss: 0.5619652995041439   1631  0.4512571096420288\n",
      "Training loss: 0.5608454261507306   1632  0.43843497335910797\n",
      "Training loss: 0.5630035357815879   1633  0.43799756467342377\n",
      "Training loss: 0.5595143224511828   1634  0.44846539199352264\n",
      "Training loss: 0.5633903741836548   1635  0.4625167101621628\n",
      "Training loss: 0.5604535788297653   1636  0.44487693905830383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.5637298098632267   1637  0.46165338158607483\n",
      "Training loss: 0.568888498204095   1638  0.4344321936368942\n",
      "Training loss: 0.5657590414796557   1639  0.45829686522483826\n",
      "Training loss: 0.5608279875346592   1640  0.45115168392658234\n",
      "Training loss: 0.5600175665957587   1641  0.45623771846294403\n",
      "Training loss: 0.5648246833256313   1642  0.46367235481739044\n",
      "Training loss: 0.5620855093002319   1643  0.45853257179260254\n",
      "Training loss: 0.5632662773132324   1644  0.45856863260269165\n",
      "Training loss: 0.5641820047582898   1645  0.45332252979278564\n",
      "Training loss: 0.5638065806456974   1646  0.45904985070228577\n",
      "Training loss: 0.5646950857979911   1647  0.45016947388648987\n",
      "Training loss: 0.5604363211563655   1648  0.45654602348804474\n",
      "Training loss: 0.5586291423865727   1649  0.4494074732065201\n",
      "Training loss: 0.5612176273550306   1650  0.4565013200044632\n",
      "Training loss: 0.5618263483047485   1651  0.45497870445251465\n",
      "Training loss: 0.5627789880548205   1652  0.44741834700107574\n",
      "Training loss: 0.56354877778462   1653  0.45055729150772095\n",
      "Training loss: 0.5579350164958409   1654  0.4542847126722336\n",
      "Training loss: 0.5650660267898014   1655  0.46347974240779877\n",
      "Training loss: 0.5600255600043705   1656  0.47012078762054443\n",
      "Training loss: 0.566870106118066   1657  0.4565463960170746\n",
      "Training loss: 0.5647995727402824   1658  0.4632253646850586\n",
      "Training loss: 0.5628247473921094   1659  0.45460210740566254\n",
      "Training loss: 0.5623349057776588   1660  0.4611625075340271\n",
      "Training loss: 0.5620708231415067   1661  0.45590390264987946\n",
      "Training loss: 0.5641363220555442   1662  0.45511728525161743\n",
      "Training loss: 0.5659346537930625   1663  0.45291513204574585\n",
      "Training loss: 0.558102907879012   1664  0.4354400634765625\n",
      "Training loss: 0.5620036380631583   1665  0.4598972648382187\n",
      "Training loss: 0.5634319697107587   1666  0.4705764651298523\n",
      "Training loss: 0.5587856471538544   1667  0.45400355756282806\n",
      "Training loss: 0.5603327027388981   1668  0.4591258019208908\n",
      "Training loss: 0.5592466379914965   1669  0.4602283537387848\n",
      "Training loss: 0.5601759936128344   1670  0.4381036311388016\n",
      "Training loss: 0.5590290980679649   1671  0.45129330456256866\n",
      "Training loss: 0.5625838765076229   1672  0.46976234018802643\n",
      "Training loss: 0.5624018354075295   1673  0.44422443211078644\n",
      "Training loss: 0.5619250578539712   1674  0.45572054386138916\n",
      "Training loss: 0.5595229608672005   1675  0.45685265958309174\n",
      "Training loss: 0.5674245187214443   1676  0.4566219300031662\n",
      "Training loss: 0.5656465249402183   1677  0.4601617157459259\n",
      "Training loss: 0.5646060747759682   1678  0.45586690306663513\n",
      "Training loss: 0.5610637388059071   1679  0.4444994479417801\n",
      "Training loss: 0.5617271363735199   1680  0.45929495990276337\n",
      "Training loss: 0.5662378668785095   1681  0.4593644440174103\n",
      "Training loss: 0.5623739830085209   1682  0.44289150834083557\n",
      "Training loss: 0.5647214736257281   1683  0.457501083612442\n",
      "Training loss: 0.5610310307570866   1684  0.45610159635543823\n",
      "Training loss: 0.5578152409621647   1685  0.4500058889389038\n",
      "Training loss: 0.5588358768395015   1686  0.44111286103725433\n",
      "Training loss: 0.5630844533443451   1687  0.44879868626594543\n",
      "Training loss: 0.562081766980035   1688  0.44297437369823456\n",
      "Training loss: 0.5586116058485848   1689  0.45496805012226105\n",
      "Training loss: 0.5620748741286141   1690  0.4644385129213333\n",
      "Training loss: 0.5572696455887386   1691  0.4474489390850067\n",
      "Training loss: 0.5569097229412624   1692  0.45867979526519775\n",
      "Training loss: 0.5618942890848432   1693  0.44424498081207275\n",
      "Training loss: 0.5624047858374459   1694  0.4539996385574341\n",
      "Training loss: 0.5597025581768581   1695  0.45020535588264465\n",
      "Training loss: 0.5624520310333797   1696  0.4474998116493225\n",
      "Training loss: 0.5625242250306266   1697  0.4638587087392807\n",
      "Training loss: 0.5594650379249028   1698  0.4424990266561508\n",
      "Training loss: 0.5618771144321987   1699  0.4517670124769211\n",
      "Training loss: 0.5610818309443337   1700  0.45301900804042816\n",
      "Training loss: 0.5622392552239555   1701  0.44477415084838867\n",
      "Training loss: 0.5611539057322911   1702  0.4436192363500595\n",
      "Training loss: 0.559897073677608   1703  0.46330640465021133\n",
      "Training loss: 0.5610113910266331   1704  0.45537325739860535\n",
      "Training loss: 0.560579674584525   1705  0.4497649520635605\n",
      "Training loss: 0.5578046057905469   1706  0.46742232143878937\n",
      "Training loss: 0.5607809466975076   1707  0.4496811479330063\n",
      "Training loss: 0.5611742820058551   1708  0.4580657035112381\n",
      "Training loss: 0.5588155090808868   1709  0.45912155508995056\n",
      "Training loss: 0.5620829973902021   1710  0.4578503519296646\n",
      "Training loss: 0.56203550526074   1711  0.4648623466491699\n",
      "Training loss: 0.5586528352328709   1712  0.4477844387292862\n",
      "Training loss: 0.5616119844572884   1713  0.457906574010849\n",
      "Training loss: 0.5599100249154227   1714  0.4345250874757767\n",
      "Training loss: 0.5583364282335553   1715  0.4455183520913124\n",
      "Training loss: 0.5641840355736869   1716  0.4552549123764038\n",
      "Training loss: 0.5593667839254651   1717  0.44568824768066406\n",
      "Training loss: 0.5604264182703835   1718  0.44970816373825073\n",
      "Training loss: 0.5599361913544791   1719  0.4494772404432297\n",
      "Training loss: 0.5590827124459403   1720  0.44769564270973206\n",
      "Training loss: 0.5590100927012307   1721  0.45068323612213135\n",
      "Training loss: 0.5613605082035065   1722  0.45635125041007996\n",
      "Training loss: 0.5562075802258083   1723  0.44265016913414\n",
      "Training loss: 0.55865164739745   1724  0.45228755474090576\n",
      "Training loss: 0.5604442741189685   1725  0.46996717154979706\n",
      "Training loss: 0.5618107829775129   1726  0.4403844624757767\n",
      "Training loss: 0.5584626240389687   1727  0.4524616003036499\n",
      "Training loss: 0.5587732791900635   1728  0.44908319413661957\n",
      "Training loss: 0.5607081438813891   1729  0.46027496457099915\n",
      "Training loss: 0.555981308221817   1730  0.44805382192134857\n",
      "Training loss: 0.5590028954403741   1731  0.45455269515514374\n",
      "Training loss: 0.5606864477906909   1732  0.4430202394723892\n",
      "Training loss: 0.5606786821569715   1733  0.4495849013328552\n",
      "Training loss: 0.5610236355236599   1734  0.45814304053783417\n",
      "Training loss: 0.5568210418735232   1735  0.4455154985189438\n",
      "Training loss: 0.5589365448270526   1736  0.4410493075847626\n",
      "Training loss: 0.5623162793261665   1737  0.45044901967048645\n",
      "Training loss: 0.5584854057856968   1738  0.44767242670059204\n",
      "Training loss: 0.5576381129877908   1739  0.45411093533039093\n",
      "Training loss: 0.5599522888660431   1740  0.4532524198293686\n",
      "Training loss: 0.5645315391676766   1741  0.4476329982280731\n",
      "Training loss: 0.5651916818959373   1742  0.44486282765865326\n",
      "Training loss: 0.5602419887270246   1743  0.45629435777664185\n",
      "Training loss: 0.5620998782770974   1744  0.45349106192588806\n",
      "Training loss: 0.559502797467368   1745  0.43864403665065765\n",
      "Training loss: 0.56320578285626   1746  0.4513244926929474\n",
      "Training loss: 0.5597578755446843   1747  0.4565184414386749\n",
      "Training loss: 0.5576680558068412   1748  0.4487624913454056\n",
      "Training loss: 0.5623659278665271   1749  0.4478117525577545\n",
      "Training loss: 0.5564036965370178   1750  0.45230528712272644\n",
      "Training loss: 0.5601730836289269   1751  0.442245751619339\n",
      "Training loss: 0.5603213033505848   1752  0.4396854490041733\n",
      "Training loss: 0.5584558248519897   1753  0.45547686517238617\n",
      "Training loss: 0.555752598813602   1754  0.4540577828884125\n",
      "Training loss: 0.5599650251013892   1755  0.44651247560977936\n",
      "Training loss: 0.5563175848552159   1756  0.4486241787672043\n",
      "Training loss: 0.5598892314093453   1757  0.44625580310821533\n",
      "Training loss: 0.5614742168358394   1758  0.4502549022436142\n",
      "Training loss: 0.553003830569131   1759  0.4526864290237427\n",
      "Training loss: 0.5536805263587407   1760  0.446463868021965\n",
      "Training loss: 0.5553053830351148   1761  0.4502954035997391\n",
      "Training loss: 0.5615872613021305   1762  0.45206719636917114\n",
      "Training loss: 0.5602093040943146   1763  0.4588678479194641\n",
      "Training loss: 0.5650701522827148   1764  0.4487505108118057\n",
      "Training loss: 0.5573798886367253   1765  0.4551311731338501\n",
      "Training loss: 0.555728588785444   1766  0.44319988787174225\n",
      "Training loss: 0.5598740918295724   1767  0.44759950041770935\n",
      "Training loss: 0.5595780930348805   1768  0.4537104666233063\n",
      "Training loss: 0.5603871984141213   1769  0.45600081980228424\n",
      "Training loss: 0.5583071282931736   1770  0.44374434649944305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.5578291969639915   1771  0.45562852919101715\n",
      "Training loss: 0.5575757069247109   1772  0.4414442479610443\n",
      "Training loss: 0.558437922171184   1773  0.448797270655632\n",
      "Training loss: 0.5596150904893875   1774  0.4538346827030182\n",
      "Training loss: 0.5636579266616276   1775  0.45527924597263336\n",
      "Training loss: 0.559743025473186   1776  0.4482942372560501\n",
      "Training loss: 0.5578833179814475   1777  0.44961313903331757\n"
     ]
    }
   ],
   "source": [
    "epochs = 2500\n",
    "for i in range(epochs):\n",
    "    running_loss = 0\n",
    "    model.train()\n",
    "    originalHidden=0\n",
    "    hidden=0\n",
    "    for data, labels in my_dataloader:\n",
    "        #print(data.shape)\n",
    "        if data.shape[0] != BatchSize:\n",
    "            #pass\n",
    "            continue;\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()    \n",
    "        logits,hidden,originalHidden = model(data,data.shape[0])\n",
    "        #print(logits.shape)\n",
    "        loss =criterion(logits,labels) #.permute(1,0,2)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    model.eval();\n",
    "    #print(originalHidden[0,0,0],hidden[0][0,0,0])\n",
    "    evalLossNum=0\n",
    "    #generateAudio('4Beats2Mel','./generatedData3/'+str(Counter))\n",
    "    for data, labels in my_validationloader:\n",
    "        if data.shape[0] != BatchSize:\n",
    "            #pass\n",
    "            continue;\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "        pred,hidden,_ = model(data,data.shape[0])  \n",
    "        loss = criterion(pred,labels)#.permute(1,0,2)\n",
    "        evalLossNum += loss.item()\n",
    "    LossOverEpoch.append(running_loss/len(my_dataloader))\n",
    "    EvalLoss.append(evalLossNum/len(my_validationloader))\n",
    "    print(str(f\"Training loss: {running_loss/len(my_dataloader)}\" +\"   \"+ str(Counter))+\"  \"+str(evalLossNum/len(my_validationloader)))\n",
    "    Counter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating audio and Spectrum image\n",
      "torch.Size([9, 25, 128])\n",
      "torch.Size([128, 25, 128])\n",
      "(3200, 2050)\n"
     ]
    }
   ],
   "source": [
    "plt.plot(LossOverEpoch)\n",
    "plt.plot(EvalLoss)\n",
    "plt.show()\n",
    "generateAudio('4Beats2Mel','./generatedData3/'+str(Counter))\n",
    "torch.save(model.cpu().state_dict(), './Demo.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in model.parameters():\n",
    "    print(p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "outputArray=[]\n",
    "h0 = torch.zeros(1, 1, 10000).cuda()\n",
    "c0 = torch.zeros(1, 1, 10000).cuda()\n",
    "for data, labels in my_testloader:\n",
    "    with torch.no_grad():\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "        print(data.shape)\n",
    "        output,_ = model.forward(data,h0,c0)\n",
    "        for i in range(SequenceLength):\n",
    "            outputArray.append(output[i,0,:].cpu().numpy())\n",
    "outputArray=np.array(outputArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outputArray.shape)\n",
    "plt.imshow(outputArray.T)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformedArray=[]\n",
    "for elem in outputArray:\n",
    "    a=np.array(np.int((n_fft/2+1)) *[1+1j])\n",
    "    a.real=elem[:np.int(n_fft/2+1)]\n",
    "    a.imag=elem[np.int(n_fft/2+1):]\n",
    "    transformedArray.append(a)\n",
    "transformedArray=np.array(transformedArray).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print((transformedArray).shape)\n",
    "Y_infered = librosa.istft(transformedArray,hop_length=hopLength)\n",
    "ipd.Audio(Y_infered,rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(y,rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(1,2,1)\n",
    "librosa.display.specshow(librosa.amplitude_to_db(transformedArray.real,\n",
    "                                                  ref=np.max),\n",
    "                          y_axis='log', x_axis='time')\n",
    "plt.title('Power spectrogram')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "librosa.display.specshow(librosa.amplitude_to_db(tensor_y.numpy()[:,:1025].T,ref=np.max),y_axis='log', x_axis='time')\n",
    "plt.title('Power spectrogram')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output=np.array(0);\n",
    "with torch.no_grad():\n",
    "        test=torch.zeros([1, 128*windowSize], dtype=torch.float32)\n",
    "       # test[0][46]=0.0;\n",
    "        output = model.forward(test)\n",
    "      #  test2=torch.ones([1, 1025], dtype=torch.float32)\n",
    "      #  test2[0][46]=0.0;\n",
    "        loss = criterion(output,torch.zeros([1, 1025], dtype=torch.float32))\n",
    "        print(loss.item())\n",
    "print(output.numpy()[0].shape,D_data[250].shape)\n",
    "plt.plot(output.numpy()[0],'r')\n",
    "#plt.plot(D_data[250],'g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(outPutMidiArray[60].T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "midiTestArray=[]\n",
    "HopSize=0.023\n",
    "timeTracker=0.0\n",
    "totalTimeTracker=0.0\n",
    "MemoryArray=np.zeros(128)\n",
    "lasttime=0;\n",
    "bpm=60\n",
    "for msg in mido.MidiFile('4Beats2Mel.mid'):\n",
    "    if not msg.is_meta:\n",
    "        totalTimeTracker+=msg.time\n",
    "        nextEventTime=lasttime+msg.time\n",
    "        while nextEventTime> timeTracker + HopSize:\n",
    "            MemoryArray[127]=((timeTracker%4) * (bpm/60.0))/4.0\n",
    "            midiTestArray.append(MemoryArray.copy())\n",
    "            timeTracker += HopSize;\n",
    "        if msg.type=='note_on':\n",
    "            MemoryArray[msg.note]+=1.0;\n",
    "        elif msg.type=='note_off':\n",
    "            MemoryArray[msg.note]-=1.0;\n",
    "        if(timeTracker+msg.time >= timeTracker + HopSize):\n",
    "            MemoryArray[127]=((timeTracker%4) * (bpm/60.0))/4.0\n",
    "            midiTestArray.append(MemoryArray.copy())\n",
    "            timeTracker += HopSize\n",
    "        lasttime += msg.time\n",
    "    else:\n",
    "        if(msg.type == 'set_tempo'):\n",
    "            bpm=60000000/msg.tempo\n",
    "midiTestArray = np.float32(np.array(midiTestArray))\n",
    "print(midiTestArray.shape)\n",
    "MainMidiTest=[]\n",
    "for i in range(midiTestArray.shape[0]):\n",
    "    temp=[]\n",
    "    for j in range(windowSize):\n",
    "        val = int(j-(np.floor(windowSize/2)))\n",
    "        val = i+val\n",
    "        if(val<0 or val+1>midiTestArray.shape[0]):\n",
    "             temp.append(np.zeros(midiTestArray.shape[1]))\n",
    "        else:\n",
    "            temp.append(midiTestArray[val])\n",
    "    MainMidiTest.append(temp)\n",
    "MainMidiTest=np.array(MainMidiTest)\n",
    "\n",
    "\n",
    "\n",
    "tensor_x_test = torch.stack([torch.Tensor(i) for i in np.abs(MainMidiTest)])\n",
    "tensor_x_test = tensor_x_test.view(tensor_x_test.shape[0],-1)\n",
    "\n",
    "testDataSet = utils.TensorDataset(tensor_x_test,torch.zeros(tensor_x_test.shape)) # create your datset\n",
    "TestLoader = utils.DataLoader(testDataSet) # create your dataloader\n",
    "\n",
    "\n",
    "model.eval()\n",
    "outputArray=[]\n",
    "for data, labels in TestLoader:\n",
    "    with torch.no_grad():\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "        output = model.forward(data)\n",
    "        outputArray.append(output[0].cpu().numpy())\n",
    "outputArray=np.array(outputArray).T\n",
    "print((outputArray).shape)\n",
    "Y_infered2 = librosa.istft(outputArray,hop_length=hopLength) \n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(1,2,1)\n",
    "librosa.display.specshow(librosa.amplitude_to_db(outputArray,\n",
    "                                                  ref=np.max),\n",
    "                          y_axis='log', x_axis='time')\n",
    "plt.title('Power spectrogram')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(midiTestArray.T,interpolation='nearest', aspect='auto')\n",
    "plt.title('Power spectrogram')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show();\n",
    "\n",
    "\n",
    "ipd.Audio(Y_infered2,rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "librosa.display.waveplot(y[:500], sr=sr);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generateAudio('4Beats2Mel','./generatedData/'+str(Counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
